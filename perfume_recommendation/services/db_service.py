import logging
import json
import pymysql
import random
from typing import List, Dict, Optional
from pathlib import Path
from datetime import datetime, timedelta
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from perfume_recommendation.models.base_model import Base, Product, Note, Spice, ProductImage, Similar, SimilarText, SimilarImage

logger = logging.getLogger(__name__)

# SQLAlchemy ì„¤ì •
DATABASE_URL = "mysql+pymysql://banghyang:banghyang@192.168.0.182:3306/banghyang"
engine = create_engine(DATABASE_URL, pool_recycle=3600)
SessionLocal = sessionmaker(bind=engine, autoflush=False, autocommit=False)

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

class DBService:
    def __init__(
        self, db_config: Dict[str, str], cache_path: str = "perfume_cache.json"
    ):
        self.db_config = db_config
        self.connection = self.connect_to_db()
        self.cache_path = Path(cache_path)
        self.cache_expiration = timedelta(days=1)  # ìºì‹± ë§Œë£Œ ì‹œê°„ (1ì¼)
        self.session = SessionLocal()

    def __del__(self):
        if hasattr(self, 'session'):
            self.session.close()

    def connect_to_db(self):
        try:
            connection = pymysql.connect(
                host=self.db_config["host"],
                port=int(self.db_config["port"]),
                user=self.db_config["user"],
                password=self.db_config["password"],
                database=self.db_config["database"],
                charset="utf8mb4",
                cursorclass=pymysql.cursors.DictCursor,
            )
            logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ!")
            return connection
        except pymysql.MySQLError as e:
            logger.error(f"ğŸš¨ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {e}")
            return None

    def fetch_brands(self) -> List[str]:
        """DBì—ì„œ ë¸Œëœë“œ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        query = "SELECT DISTINCT brand FROM product;"
        try:
            with self.connection.cursor() as cursor:
                cursor.execute(query)
                brands = [row["brand"] for row in cursor.fetchall()]
            
            logger.info(f"âœ… ì´ {len(brands)}ê°œì˜ ë¸Œëœë“œ ì¡°íšŒ ì™„ë£Œ")
            return brands
        except pymysql.MySQLError as e:
            logger.error(f"ğŸš¨ ë¸Œëœë“œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
    
    def fetch_spices_by_line(self, line_id: int) -> List[Dict]:
        """íŠ¹ì • ê³„ì—´(line_id)ì— ì†í•˜ëŠ” í–¥ë£Œ(spice) ëª©ë¡ ì¡°íšŒ"""
        try:
            query = """
                SELECT id, name_kr 
                FROM spice 
                WHERE line_id = %s;
            """
            
            with self.connection.cursor() as cursor:
                cursor.execute(query, (line_id,))
                spices = cursor.fetchall()
            
            if not spices:
                logger.warning(f"âš ï¸ í•´ë‹¹ ê³„ì—´ ID({line_id})ì— ì†í•˜ëŠ” í–¥ë£Œê°€ ì—†ìŠµë‹ˆë‹¤.")
                return []

            logger.info(f"âœ… ê³„ì—´ ID({line_id})ì— í•´ë‹¹í•˜ëŠ” í–¥ë£Œ {len(spices)}ê°œ ì¡°íšŒ ì™„ë£Œ")
            return spices

        except pymysql.MySQLError as e:
            logger.error(f"ğŸš¨ í–¥ë£Œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []

    def fetch_line_data(self) -> List[Dict]:
        """
        line í…Œì´ë¸”ì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ì—¬ ë°˜í™˜.

        Returns:
            List[Dict]: line í…Œì´ë¸”ì˜ ë°ì´í„°ë¥¼ í¬í•¨í•œ ë¦¬ìŠ¤íŠ¸
        """
        query = "SELECT * FROM line;"
        try:
            with self.connection.cursor() as cursor:
                cursor.execute(query)
                lines = cursor.fetchall()

            logger.info(f"âœ… line í…Œì´ë¸” ë°ì´í„° {len(lines)}ê°œ ì¡°íšŒ ì™„ë£Œ")
            return lines
        except pymysql.MySQLError as e:
            logger.error(f"ğŸš¨ ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []
    
    def get_perfumes_by_middel_notes(self, spice_ids: List[int]) -> List[Dict]:
        """MIDDLE íƒ€ì…ì˜ ë…¸íŠ¸ë¥¼ í¬í•¨í•œ í–¥ìˆ˜ë¥¼ ê²€ìƒ‰"""
        try:
            spice_ids_str = ",".join(map(str, spice_ids))
            query = f"""
                SELECT DISTINCT
                    p.id, 
                    p.brand, 
                    p.name_kr, 
                    p.size_option as volume,
                    COUNT(DISTINCT n.spice_id) as matching_count
                FROM product p
                JOIN note n ON p.id = n.product_id
                WHERE p.category_id = 1
                AND n.spice_id IN ({spice_ids_str})
                AND n.note_type = 'MIDDLE'
                GROUP BY p.id, p.brand, p.name_kr, p.size_option
                ORDER BY matching_count DESC;
            """

            with self.connection.cursor() as cursor:
                cursor.execute(query)
                perfumes = cursor.fetchall()
                logger.info(f"âœ… ì „ì²´ ë§¤ì¹­ë˜ëŠ” í–¥ìˆ˜ {len(perfumes)}ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

                return perfumes

        except pymysql.MySQLError as e:
            logger.error(f"ğŸš¨ í–¥ìˆ˜ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def cache_perfume_data(self, force: bool = False) -> None:
        """
        DBì˜ í–¥ìˆ˜ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ìºì‹±. `force=True` ë˜ëŠ” ë³€ê²½ ì‚¬í•­ì´ ìˆì„ ê²½ìš° ê°±ì‹ .
        """
        existing_products = self.load_cached_perfume_data(check_only=True)

        query = """
        SELECT 
            p.id, p.name_kr, p.name_en, p.brand, p.main_accord, p.category_id
        FROM product p
        """
        try:
            with self.connection.cursor() as cursor:
                cursor.execute(query)
                new_products = cursor.fetchall()

            # ë°ì´í„° ë³€ê²½ ì—¬ë¶€ í™•ì¸
            if not force and self.is_cache_up_to_date(existing_products, new_products):
                logger.info(f"âœ… ìºì‹± ë°ì´í„°ê°€ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤: {self.cache_path}")
                return

            # ìºì‹± íŒŒì¼ ì €ì¥
            with open(self.cache_path, "w", encoding="utf-8") as f:
                json.dump(new_products, f, ensure_ascii=False, indent=4)

            logger.info(f"âœ… í–¥ìˆ˜ ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ìºì‹± ì™„ë£Œ: {self.cache_path}")

        except pymysql.MySQLError as e:
            logger.error(f"ğŸš¨ ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ ë°œìƒ: {e}")

    def load_cached_perfume_data(self, check_only: bool = False) -> List[Dict]:
        """
        ìºì‹±ëœ ë°ì´í„°ë¥¼ ë¡œë“œ. ìºì‹± íŒŒì¼ì´ ì—†ìœ¼ë©´ check_only=Falseì¼ ë•Œ ìƒˆë¡œ ìƒì„±.
        """
        if not self.cache_path.exists():
            if check_only:
                return []
            logger.info("ìºì‹± íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            self.cache_perfume_data()

        with open(self.cache_path, "r", encoding="utf-8") as f:
            products = json.load(f)

        logger.info(f"âœ… ìºì‹±ëœ í–¥ìˆ˜ ë°ì´í„° {len(products)}ê°œ ë¡œë“œ")
        return products

    def is_cache_up_to_date(self, existing_products: List[Dict], new_products: List[Dict]) -> bool:
        """
        ê¸°ì¡´ ìºì‹± ë°ì´í„°ì™€ ìƒˆë¡œ ê°€ì ¸ì˜¨ DB ë°ì´í„°ë¥¼ ë¹„êµí•˜ì—¬ ë³€ê²½ ì‚¬í•­ì´ ìˆëŠ”ì§€ í™•ì¸.
        """
        existing_dict = {item['id']: item for item in existing_products}
        new_dict = {item['id']: item for item in new_products}

        # ìƒˆë¡œìš´ IDê°€ ì¶”ê°€ë˜ì—ˆê±°ë‚˜ ê¸°ì¡´ ë°ì´í„°ê°€ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
        if set(existing_dict.keys()) != set(new_dict.keys()):
            logger.info("ğŸ”„ ìƒˆë¡œìš´ í–¥ìˆ˜ ë°ì´í„°ê°€ ì¶”ê°€ë¨. ìºì‹±ì„ ê°±ì‹ í•©ë‹ˆë‹¤.")
            return False

        for key in new_dict.keys():
            if existing_dict[key] != new_dict[key]:  # ë°ì´í„° ë³€ê²½ í™•ì¸
                logger.info("ğŸ”„ ê¸°ì¡´ í–¥ìˆ˜ ë°ì´í„°ê°€ ë³€ê²½ë¨. ìºì‹±ì„ ê°±ì‹ í•©ë‹ˆë‹¤.")
                return False

        return True

    def force_generate_cache(self) -> None:
        """
        ê°•ì œë¡œ JSON ìºì‹± íŒŒì¼ì„ ìƒì„±í•˜ëŠ” ë©”ì„œë“œ.
        """
        logger.info("ê°•ì œ ìºì‹± ìƒì„± ìš”ì²­ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")
        self.cache_perfume_data(force=True)
        logger.info("âœ… ê°•ì œ ìºì‹± ìƒì„± ì™„ë£Œ.")


    def get_spices_by_names(self, note_names: List[str]) -> List[Dict]:
        """í–¥ë£Œ ì´ë¦„ìœ¼ë¡œ IDë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        try:
            # LIKE ê²€ìƒ‰ì„ ìœ„í•œ íŒ¨í„´ ìƒì„±
            patterns = [f"name_kr LIKE '%{note.strip()}%'" for note in note_names] # í•œê¸€ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰
            where_clause = " OR ".join(patterns) # OR ì¡°ê±´ìœ¼ë¡œ ì—°ê²°
            
            query = f"""
                SELECT id, name_kr
                FROM spice 
                WHERE {where_clause}
                ORDER BY 
                    CASE 
                        WHEN name_kr IN ({', '.join([f"'{note.strip()}'" for note in note_names])}) THEN 0 
                        ELSE 1 
                    END,
                    name_kr;
            """
            
            with self.connection.cursor() as cursor:
                cursor.execute(query) # ì¿¼ë¦¬ ì‹¤í–‰
                result = cursor.fetchall() # ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
                
                logger.info(f"âœ… ìš”ì²­ëœ í–¥ë£Œ: {note_names}")
                logger.info(f"âœ… ë§¤ì¹­ëœ í–¥ë£Œ: {[r['name_kr'] for r in result]}")
                
                return result
                
        except pymysql.MySQLError as e:
            logger.error(f"ğŸš¨ í–¥ë£Œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    def get_diffusers_by_spice_ids(self, spice_ids: List[int]) -> List[Dict]:
        """í•´ë‹¹ í–¥ë£Œê°€ í•˜ë‚˜ë¼ë„ í¬í•¨ëœ ë””í“¨ì €ë“¤ ì¤‘ì—ì„œ ëœë¤í•˜ê²Œ 2ê°œë¥¼ ì„ íƒí•©ë‹ˆë‹¤."""
        try:
            spice_ids_str = ",".join(map(str, spice_ids))
            
            # ë¨¼ì € ì „ì²´ ë§¤ì¹­ë˜ëŠ” ë””í“¨ì € ìˆ˜ë¥¼ í™•ì¸
            count_query = f"""
                SELECT COUNT(DISTINCT p.id) as total_count
                FROM product p
                JOIN note n ON p.id = n.product_id
                WHERE p.category_id = 2
                AND n.spice_id IN ({spice_ids_str})
                AND p.name_kr NOT LIKE '%ì¹´ ë””í“¨ì €%'
            """
            
            # ê·¸ ë‹¤ìŒ ëœë¤í•˜ê²Œ 2ê°œ ì„ íƒ
            main_query = f"""
                SELECT DISTINCT
                    p.id, 
                    p.brand, 
                    p.name_kr, 
                    p.size_option as volume,
                    p.content,
                    COUNT(DISTINCT n.spice_id) as matching_count,
                    GROUP_CONCAT(DISTINCT s.name_kr) as included_notes
                FROM product p
                JOIN note n ON p.id = n.product_id
                JOIN spice s ON n.spice_id = s.id
                WHERE p.category_id = 2
                AND n.spice_id IN ({spice_ids_str})
                AND p.name_kr NOT LIKE '%ì¹´ ë””í“¨ì €%'
                GROUP BY p.id, p.brand, p.name_kr, p.size_option, p.content
                ORDER BY RAND()
                LIMIT 2
            """
            
            with self.connection.cursor() as cursor:
                # ì „ì²´ ê°œìˆ˜ í™•ì¸
                cursor.execute(count_query)
                total_count = cursor.fetchone()['total_count']
                logger.info(f"âœ… ì „ì²´ ë§¤ì¹­ë˜ëŠ” ë””í“¨ì €: {total_count}ê°œ")
                
                # ëœë¤ ì„ íƒ
                cursor.execute(main_query)
                result = cursor.fetchall()
                
                # ì„ íƒëœ ë””í“¨ì € ë¡œê¹…
                for diffuser in result:
                    logger.info(
                        f"âœ… ì„ íƒë¨: {diffuser['name_kr']} (ID: {diffuser['id']}) - "
                        f"í¬í•¨ í–¥ë£Œ: {diffuser['included_notes']}"
                    )
                
                return result
                
        except pymysql.MySQLError as e:
            logger.error(f"ğŸš¨ ë””í“¨ì € ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
        
    # ORMì„ ì‚¬ìš©í•˜ëŠ” ìƒˆë¡œìš´ ë©”ì„œë“œë“¤
    def get_product_by_id(self, product_id: int):
        """SQLAlchemyë¥¼ ì‚¬ìš©í•˜ì—¬ ì œí’ˆ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
        try:
            return self.session.query(Product).filter(Product.id == product_id).first()
        except Exception as e:
            logger.error(f"ğŸš¨ ì œí’ˆ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    def get_similar_products_by_text(self, product_id: int) -> List[Dict]:
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ ìœ ì‚¬ë„ë¡œ ë¹„ìŠ·í•œ ì œí’ˆì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        try:
            similar_products = (
                self.session.query(
                    Product.id,
                    Product.brand,
                    Product.name_kr,
                    Product.size_option.label('volume'),
                    SimilarText.similarity_score
                )
                .join(SimilarText, Product.id == SimilarText.similar_product_id)
                .filter(SimilarText.product_id == product_id)
                .order_by(SimilarText.similarity_score.desc())
                .limit(5)
                .all()
            )
            logger.info(f"âœ… í…ìŠ¤íŠ¸ ê¸°ë°˜ ìœ ì‚¬ ì œí’ˆ {len(similar_products)}ê°œ ì¡°íšŒ ì™„ë£Œ")
            return [dict(zip(['id', 'brand', 'name_kr', 'volume', 'similarity_score'], p)) for p in similar_products]
        except Exception as e:
            logger.error(f"ğŸš¨ í…ìŠ¤íŠ¸ ê¸°ë°˜ ìœ ì‚¬ ì œí’ˆ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []


# ìºì‹± ìƒì„± ê¸°ëŠ¥ ì‹¤í–‰
if __name__ == "__main__":
    import os

    # DB ì„¤ì •
    db_config = {
        "host": os.getenv("DB_HOST"),
        "port": os.getenv("DB_PORT"),
        "user": os.getenv("DB_USER"),
        "password": os.getenv("DB_PASSWORD"),
        "database": os.getenv("DB_NAME"),
    }

    # DB ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    db_service = DBService(db_config=db_config)

    # ê°•ì œ ìºì‹± ìƒì„± ì‹¤í–‰
    db_service.force_generate_cache()
    print("í–¥ìˆ˜ ë°ì´í„° ê°•ì œ ìºì‹± ì™„ë£Œ!")
