from sqlalchemy.orm import Session
from sentence_transformers import SentenceTransformer
from functools import lru_cache
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from .db_service import Product, Note
from perfume_recommendation.embedding_utils import save_text_embedding, load_text_embedding  # âœ… ìºì‹œ ì¶”ê°€

# âœ… í…ìŠ¤íŠ¸ ëª¨ë¸ ì„¤ì •
TEXT_MODEL_TYPE = "mpnet"
TEXT_MODEL_CONFIG = {
    "mpnet": "sentence-transformers/all-mpnet-base-v2",
    "minilm": "sentence-transformers/all-MiniLM-L6-v2",
}

text_model = SentenceTransformer(TEXT_MODEL_CONFIG[TEXT_MODEL_TYPE])


def get_similar_text_embedding(text: str):
    """í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ ìºì‹œì—ì„œ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜, ìƒˆë¡œ ê³„ì‚°"""

    # âœ… ë¨¼ì € ìºì‹œì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸° ì‹œë„
    cached_embedding = load_text_embedding(text)
    if cached_embedding is not None:
        print(f"âœ… ìºì‹œì—ì„œ í…ìŠ¤íŠ¸ ì„ë² ë”© ë¶ˆëŸ¬ì˜´: {text}")  # ğŸš€ ë””ë²„ê¹… ë©”ì‹œì§€ ì¶”ê°€
        return cached_embedding  # ìºì‹œê°€ ìˆìœ¼ë©´ ë°”ë¡œ ë°˜í™˜

    # ìºì‹œì— ì—†ìœ¼ë©´ ìƒˆë¡œ ê³„ì‚°
    embedding = text_model.encode(text)

    # âœ… ìƒˆë¡œ ê³„ì‚°ëœ ì„ë² ë”©ì„ ì €ì¥ (JSON ìºì‹±)
    save_text_embedding(text, embedding)
    return embedding


def find_similar_texts(product_id: int, db: Session, top_n: int = 5):
    """í…ìŠ¤íŠ¸ ê¸°ë°˜ ìœ ì‚¬ í–¥ìˆ˜ ê²€ìƒ‰"""
    # 1. ê¸°ì¤€ ì œí’ˆ ì •ë³´ ì¡°íšŒ
    product = db.query(Product).filter(Product.id == product_id).first()
    if not product:
        return []

    # 2. ê¸°ì¤€ ì œí’ˆì˜ ë…¸íŠ¸ ì •ë³´ ì¡°íšŒ
    notes = db.query(Note).filter(Note.product_id == product_id).all()
    note_info = " ".join([note.note_type for note in notes])

    # 3. ê¸°ì¤€ ì œí’ˆì˜ ë©”ì¸ ì–´ì½”ë“œì™€ ì„¤ëª… ì •ë³´
    product_info = f"{product.main_accord} {product.content if product.content else ''}"

    # 4. ê¸°ì¤€ ì œí’ˆì˜ ì„ë² ë”© ìƒì„±
    target_embedding = np.mean(
        [
            get_similar_text_embedding(note_info) * 2.0,  # ë…¸íŠ¸ ì •ë³´ ê°€ì¤‘ì¹˜
            get_similar_text_embedding(product.main_accord) * 1.5,  # ë©”ì¸ ì–´ì½”ë“œ ê°€ì¤‘ì¹˜
            get_similar_text_embedding(product_info),  # ì œí’ˆ ì„¤ëª…
        ],
        axis=0,
    )

    # 5. ë‹¤ë¥¸ í–¥ìˆ˜ ì œí’ˆë“¤ê³¼ ìœ ì‚¬ë„ ê³„ì‚°
    similarities = []
    all_products = (
        db.query(Product)
        .filter(Product.category_id == 1, Product.id != product_id)
        .all()
    )

    for other_product in all_products:
        # ë‹¤ë¥¸ ì œí’ˆì˜ ë…¸íŠ¸ ì •ë³´
        other_notes = db.query(Note).filter(Note.product_id == other_product.id).all()
        other_note_info = " ".join([note.note_type for note in other_notes])

        # ë‹¤ë¥¸ ì œí’ˆì˜ ë©”ì¸ ì–´ì½”ë“œì™€ ì„¤ëª… ì •ë³´
        other_product_info = f"{other_product.main_accord} {other_product.content if other_product.content else ''}"

        # ë‹¤ë¥¸ ì œí’ˆì˜ ì„ë² ë”© ìƒì„±
        other_embedding = np.mean(
            [
                get_similar_text_embedding(other_note_info) * 2.0,
                get_similar_text_embedding(other_product.main_accord) * 1.5,
                get_similar_text_embedding(other_product_info),
            ],
            axis=0,
        )

        # ìœ ì‚¬ë„ ê³„ì‚°
        similarity = cosine_similarity([target_embedding], [other_embedding])[0][0]
        similarities.append({"product_id": other_product.id, "similarity": similarity})

    # 6. ìœ ì‚¬ë„ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ í›„ ìƒìœ„ Nê°œ ì„ íƒ
    sorted_similarities = sorted(
        similarities, key=lambda x: x["similarity"], reverse=True
    )[:top_n]
    return sorted_similarities
