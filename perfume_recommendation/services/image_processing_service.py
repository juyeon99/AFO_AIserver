import os
import torch
from PIL import Image
from transformers import AutoProcessor, AutoModelForCausalLM
from io import BytesIO

# OpenMP ì¶©ëŒ ë°©ì§€ ì„¤ì •
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
os.environ["OMP_NUM_THREADS"] = "1"

class ImageProcessingService:
    def __init__(self):
        """Florence-2 ëª¨ë¸ ë° í”„ë¡œì„¸ì„œë¥¼ ì´ˆê¸°í™”"""
        try:
            print("ğŸ”¹ Florence-2 ëª¨ë¸ ë¡œë“œ ì¤‘...")
            self.device = "cuda:0" if torch.cuda.is_available() else "cpu"
            self.torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32

            # ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ
            self.model = AutoModelForCausalLM.from_pretrained(
                "microsoft/Florence-2-large",
                torch_dtype=self.torch_dtype,
                trust_remote_code=True
            ).to(self.device)

            self.processor = AutoProcessor.from_pretrained(
                "microsoft/Florence-2-large",
                trust_remote_code=True
            )

            print("âœ… Florence-2 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        
        except Exception as e:
            print(f"ğŸš¨ ëª¨ë¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise RuntimeError("ğŸš¨ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ!")

    def process_image(self, image_data: bytes) -> dict:
        """ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì„¤ëª…ì„ ìƒì„±"""
        try:
            print("ğŸ”¹ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘...")
            image = Image.open(BytesIO(image_data)).convert("RGB")
            image = image.resize((512, 512))

            # í”„ë¡¬í”„íŠ¸ ì„¤ì •
            prompt = "<MORE_DETAILED_CAPTION>"
            inputs = self.processor(text=prompt, images=image, return_tensors="pt")

            # ì¥ì¹˜ ë° ë°ì´í„° íƒ€ì… ë³€í™˜
            inputs["input_ids"] = inputs["input_ids"].to(self.device, dtype=torch.long)
            inputs["pixel_values"] = inputs["pixel_values"].to(self.device, dtype=torch.float16)

            # ëª¨ë¸ ì˜ˆì¸¡
            generated_ids = self.model.generate(
                input_ids=inputs["input_ids"],
                pixel_values=inputs["pixel_values"],
                max_new_tokens=512,
                num_beams=5,
                do_sample=True,
                top_k=50,
                temperature=0.7
            )

            # í…ìŠ¤íŠ¸ ë””ì½”ë”©
            description = self.processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
            print("âœ… ìƒì„±ëœ ì„¤ëª…:", description)

            # ê°„ë‹¨í•œ ê°ì • ë¶„ì„ ì¶”ê°€ (ì˜ˆì‹œ)
            if "happy" in description.lower() or "cheerful" in description.lower():
                feeling = "Positive"
            elif "dark" in description.lower() or "sad" in description.lower():
                feeling = "Negative"
            else:
                feeling = "Neutral"

            return {"description": description, "feeling": feeling}

        except Exception as e:
            print(f"ğŸš¨ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {"error": f"ğŸš¨ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"}
