import json, random
import logging, chromadb, json
from typing import Optional, Tuple
from models.img_llm_client import GPTClient
from .db_service import DBService
from services.prompt_loader import PromptLoader
from fastapi import HTTPException
from chromadb.utils import embedding_functions

logger = logging.getLogger(__name__)

chroma_client = chromadb.PersistentClient(path="chroma_db")
embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(model_name="snunlp/KLUE-SRoBERTa-Large-SNUExtended-klueNLI-klueSTS")

class LLMService:
    def __init__(self, gpt_client: GPTClient, db_service: DBService, prompt_loader: PromptLoader):
        self.gpt_client = gpt_client
        self.db_service = db_service
        self.prompt_loader = prompt_loader

        self.all_diffusers = self.db_service.load_cached_diffuser_data()
        self.diffuser_scent_descriptions = self.db_service.load_diffuser_scent_cache()

        if not self.all_diffusers:
            raise RuntimeError("No diffuser data available for initialization.")

        # Initialize vector database
        self.collection = self.initialize_vector_db(self.all_diffusers, self.diffuser_scent_descriptions)

    def process_input(self, user_input: str, image_caption: Optional[str] = None) -> Tuple[str, Optional[int]]:
        """
        ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ì˜ë„ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.
        """
        try:
            logger.info(f"Received user input: {user_input}")  # ì…ë ¥ ë¡œê·¸

            # ì˜ë„ ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸
            intent_prompt = (
                f"ì…ë ¥: {user_input}\n"
                f"ë‹¤ìŒ ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ë¶„ë¥˜í•˜ì„¸ìš”.\n\n"
                f"ì¼ë°˜ì ì¸ í‚¤ì›Œë“œë¼ê³  ë³¼ ìˆ˜ ì—†ëŠ” í–¥ìˆ˜ ì¶”ì²œì€ (2) ì¼ë°˜ ëŒ€í™”ë¡œ ë¶„ë¥˜í•´ì•¼ í•©ë‹ˆë‹¤.\n\n"
                f"ì˜ˆì‹œ) user_input = ë‚˜ ì˜¤ëŠ˜ ê¸°ë¶„ì´ ë„ˆë¬´ ìš°ìš¸í•´. ê·¸ë˜ì„œ ì´ëŸ° ê¸°ë¶„ì„ ë–¨ì³ë‚¼ ìˆ˜ ìˆëŠ” í”Œë¡œëŸ´ ê³„ì—´ì˜ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•´ì¤˜ (1) í–¥ìˆ˜ ì¶”ì²œ \n"
                f"ì˜ˆì‹œ) user_input = í–¥ìˆ˜ë¥¼ ì¶”ì²œë°›ê³  ì‹¶ì€ë° ë­ ì¢‹ì€ ê±° ìˆì–´? (2) ì¼ë°˜ ëŒ€í™”\n"
                f"ì˜ˆì‹œ) user_input = í–¥ìˆ˜ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”. ë¼ë©´ (2) ì¼ë°˜ ëŒ€í™”ë¡œ ë¶„ë¥˜í•´ì•¼ í•©ë‹ˆë‹¤.\n\n"
                f"ì˜ë„: (1) í–¥ìˆ˜ ì¶”ì²œ, (2) ì¼ë°˜ ëŒ€í™”, (3) íŒ¨ì…˜ í–¥ìˆ˜ ì¶”ì²œ, (4) ì¸í…Œë¦¬ì–´ ê¸°ë°˜ ë””í“¨ì € ì¶”ì²œ, (5) í…Œë¼í”¼ ëª©ì  í–¥ìˆ˜/ë””í“¨ì € ì¶”ì²œ"
            )

            intent = self.gpt_client.generate_response(intent_prompt).strip()
            logger.info(f"Detected intent: {intent}")  # ì˜ë„ ê°ì§€ ê²°ê³¼

            if "1" in intent:
                logger.info("ğŸ’¡ ì¼ë°˜ í–¥ìˆ˜ ì¶”ì²œ ì‹¤í–‰")
                return "recommendation", self.generate_recommendation_response(user_input)

            if "3" in intent:
                logger.info("ğŸ‘• íŒ¨ì…˜ ê¸°ë°˜ í–¥ìˆ˜ ì¶”ì²œ ì‹¤í–‰ (modeëŠ” recommendation ìœ ì§€)")
                return "recommendation", self.fashion_based_generate_recommendation_response(user_input, image_caption)
            
            if "4" in intent:
                logger.info("ğŸ¡ ê³µê°„ ê¸°ë°˜ ë””í“¨ì € ì¶”ì²œ ì‹¤í–‰")
                return "recommendation", self.generate_interior_design_based_recommendation_response(user_input, image_caption)
            
            if "5" in intent:
                logger.info("ğŸŒ í…Œë¼í”¼ ëª©ì  í–¥ìˆ˜ ì¶”ì²œ ì‹¤í–‰")
                return "recommendation", self.generate_therapeutic_purpose_recommendation_response(user_input)

            return "chat", self.generate_chat_response(user_input)

        except Exception as e:
            logger.error(f"Error processing input '{user_input}': {e}")
            raise HTTPException(status_code=500, detail="Failed to classify user intent.")

    def extract_keywords_from_input(self, user_input: str, image_caption: Optional[str] = None) -> dict:
        """ì‚¬ìš©ì ì…ë ¥ì—ì„œ ê³„ì—´ê³¼ ë¸Œëœë“œë¥¼ ë¶„ì„í•˜ê³  ê³„ì—´ IDì™€ ë¸Œëœë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
        try:
            logger.info(f"ğŸ” ì…ë ¥ëœ í…ìŠ¤íŠ¸ì—ì„œ í–¥ ê³„ì—´ê³¼ ë¸Œëœë“œ ë¶„ì„ ì‹œì‘: {user_input}")

            # 1. DBì—ì„œ ê³„ì—´ ë° ë¸Œëœë“œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            line_data = self.db_service.fetch_line_data()
            line_mapping = {line["name"]: line["id"] for line in line_data}
            brand_list = self.db_service.fetch_brands()

            # fashion_to_line_mapping = {
            #     # ìºì£¼ì–¼ ìŠ¤íƒ€ì¼
            #     "ìºì£¼ì–¼": "Fruity",
            #     "ëŒ„ë”” ìºì£¼ì–¼": "Woody",  # ëŒ„ë””í•˜ë©´ì„œë„ ì„¸ë ¨ëœ ìŠ¤íƒ€ì¼
            #     "ì•„ë©”ì¹´ì§€": "Green",  # ë‚´ì¶”ëŸ´í•˜ë©´ì„œ ë¹ˆí‹°ì§€í•œ ëŠë‚Œ  

            #     # í´ë˜ì‹ & í¬ë©€ ìŠ¤íƒ€ì¼
            #     "í´ë˜ì‹": "Woody",
            #     "ë¹„ì¦ˆë‹ˆìŠ¤ í¬ë©€": "Musk",  # ì •ì¥ ì°©ì¥ì— ì–´ìš¸ë¦¬ëŠ” ì°¨ë¶„í•œ í–¥
            #     "ë¹„ì¦ˆë‹ˆìŠ¤ ìºì£¼ì–¼": "Citrus",  # ê°€ë²¼ìš´ í¬ë©€ ë£©ì— ì˜ ë§ëŠ” ì‹œì›í•œ í–¥
            #     "ì  í‹€í•œ ìŠ¤íƒ€ì¼": "Powdery",  # ë¶€ë“œëŸ¬ìš´ ë¶„ìœ„ê¸°ë¥¼ ì£¼ëŠ” Powdery í–¥  

            #     # ìŠ¤íŠ¸ë¦¿ & ìœ ë‹ˆí¬ ìŠ¤íƒ€ì¼
            #     "ìŠ¤íŠ¸ë¦¿": "ìŠ¤íŒŒì´ì‹œ",
            #     "í…Œí¬ì›¨ì–´": "ì•„ë¡œë§ˆí‹±",  # SFì ì´ê³  ë¯¸ë˜ì ì¸ ëŠë‚Œì˜ íŒ¨ì…˜ê³¼ ì–´ìš¸ë¦¼
            #     "ê³ í”„ì½”ì–´": "Green",  # ë“±ì‚° ë° ì•„ì›ƒë„ì–´ ëŠë‚Œì˜ ìŠ¤íƒ€ì¼ê³¼ ìì—°ìŠ¤ëŸ¬ìš´ í–¥
            #     "í‘í¬ ìŠ¤íƒ€ì¼": "Tobacco Leather",  # ê°•ë ¬í•œ ë½ & í‘í¬ ë¬´ë“œ  

            #     # ìŠ¤í¬í‹° & ì•¡í‹°ë¸Œ ìŠ¤íƒ€ì¼
            #     "ìŠ¤í¬í‹°": "Citrus",
            #     "ëŸ¬ë„ˆ ìŠ¤íƒ€ì¼": "Aquatic",  # í™œë™ì ì´ê³  ì‹ ì„ í•œ ëŠë‚Œ  
            #     "í…Œë‹ˆìŠ¤ ë£©": "Fougere",  # í´ë˜ì‹í•˜ë©´ì„œë„ ê¹¨ë—í•œ í–¥  

            #     # ë¹ˆí‹°ì§€ & ê°ì„±ì ì¸ ìŠ¤íƒ€ì¼
            #     "ë¹ˆí‹°ì§€": "Oriental",
            #     "ë¡œë§¨í‹± ìŠ¤íƒ€ì¼": "Floral",  # ë¶€ë“œëŸ½ê³  ë‹¬ì½¤í•œ ë¶„ìœ„ê¸°ì˜ ìŠ¤íƒ€ì¼  
            #     "ë³´í—¤ë¯¸ì•ˆ": "Musk",  # ìì—°ìŠ¤ëŸ½ê³  ëª½í™˜ì ì¸ ë¶„ìœ„ê¸°  
            #     "ë ˆíŠ¸ë¡œ íŒ¨ì…˜": "Aldehyde",  # 70~80ë…„ëŒ€ ìŠ¤íƒ€ì¼ê³¼ ì–´ìš¸ë¦¬ëŠ” í´ë˜ì‹í•œ í–¥  

            #     # ëª¨ë˜ & ë¯¸ë‹ˆë©€ ìŠ¤íƒ€ì¼
            #     "ëª¨ë˜": "Woody",
            #     "ë¯¸ë‹ˆë©€": "Powdery",  # ê¹¨ë—í•˜ê³  ë‹¨ì •í•œ ë¶„ìœ„ê¸°  
            #     "ì˜¬ ë¸”ë™ ë£©": "Tobacco Leather",  # ê°•ë ¬í•˜ë©´ì„œ ì‹œí¬í•œ ë¬´ë“œ  
            #     "í™”ì´íŠ¸ í†¤ ìŠ¤íƒ€ì¼": "Musk",  # ê¹¨ë—í•˜ê³  ë¶€ë“œëŸ¬ìš´ ëŠë‚Œ  

            #     # ë…íŠ¹í•œ ì»¨ì…‰ ìŠ¤íƒ€ì¼
            #     "ì•„ë°©ê°€ë¥´ë“œ": "Tobacco Leather",  # ì˜ˆìˆ ì ì¸ ìŠ¤íƒ€ì¼ê³¼ ì–´ìš¸ë¦¬ëŠ” ê°€ì£½ í–¥  
            #     "ê³ ë”• ìŠ¤íƒ€ì¼": "Oriental",  # ë‹¤í¬í•˜ë©´ì„œ ë¬´ê²Œê° ìˆëŠ” í–¥  
            #     "ì½”ìŠ¤í”„ë ˆ": "Gourmand",  # ë‹¬ì½¤í•˜ë©´ì„œ ê°œì„± ê°•í•œ ìŠ¤íƒ€ì¼  
            # }
            
            # 2. GPTë¥¼ ì´ìš©í•´ ì…ë ¥ì—ì„œ í–¥ ê³„ì—´ê³¼ ë¸Œëœë“œ ì¶”ì¶œ
            keywords_prompt = (
                "The following is a perfume recommendation request. Extract the fragrance family and brand names from the user_input and image_caption.\n"
                f"Fragrance families: {', '.join(line_mapping.keys())}\n"
                f"Brand list: {', '.join(brand_list)}\n\n"

                "Additional rules: If the user_input and the image_caption is a description of a fashion style, use the corresponding fragrance family from the following fashion styles.\n"
                "Additional rules: If the user_input is a description of a date or a specific situation, use the corresponding fragrance family for the situation.\n"
                "Additional rules: Infer the user's style or vibe from the the user_input or image_caption (e.g., sporty, romantic, vintage, etc.) and recommend a fragrance family(line) based on that.\n\n"
                
                "### Fashion style to output fragrance family(line) mapping example:\n"
                "1. Fashion style: Casual style -> line: **Fruity**\n"
                "2. Fashion style: Dandy Casual -> line: **Woody**\n"
                "3. Fashion style: American Casual -> line: **Green**\n"
                "4. Fashion style: Classic -> line: **Woody**\n"
                "5. Fashion style: Business Formal -> line: **Musk**\n"
                "6. Fashion style: Business Casual -> line: **Citrus**\n"
                "7. Fashion style: Gentle Style -> line: **Powdery**\n"
                "8. Fashion style: Street -> line: **Spicy**\n"
                "9. Fashion style: Techwear -> line: **Aromatic**\n"
                "10. Fashion style: Gorp Core -> line: **Green**\n"
                "11. Fashion style: Punk Style -> line: **Tobacco Leather**\n"
                "12. Fashion style: Sporty -> line: **Citrus**\n"
                "13. Fashion style: Runner Style -> line: **Aquatic**\n"
                "14. Fashion style: Tennis Look -> line: **Fougere**\n"
                "15. Fashion style: Vintage -> line: **Oriental**\n"
                "16. Fashion style: Romantic Style -> line: **Floral**\n"
                "17. Fashion style: Bohemian -> line: **Musk**\n"
                "18. Fashion style: Retro Fashion -> line: **Aldehyde**\n"
                "19. Fashion style: Modern -> line: **Woody**\n"
                "20. Fashion style: Minimal -> line: **Powdery**\n"
                "21. Fashion style: All Black Look -> line: **Tobacco Leather**\n"
                "22. Fashion style: White Tone Style -> line: **Musk**\n"
                "23. Fashion style: Avant-garde -> line: **Tobacco Leather**\n"
                "24. Fashion style: Gothic Style -> line: **Oriental**\n"
                "25. Fashion style: Cosplay -> line: **Gourmand**\n\n"

                "### Important rule: The 'line' must **never** be null. It should always correspond to **one of [{', '.join(line_mapping.keys())}]**.\n"
                "### NOTE: The 'brands' list can be empty.\n\n"
                
                "### The output format must be **JSON**:\n"
                "{\n"
                '  "line": "Woody",\n'
                '  "brands": ["ìƒ¤ë„¬", "ë”¥í‹°í¬"]\n'
                "}"

                f"\n\n### user_input: {user_input}"
            )

            if keywords_prompt is not None:
                keywords_prompt += f"\n### image_caption: {image_caption}"
            
            response_text = self.gpt_client.generate_response(keywords_prompt).strip()
            logger.info(f"ğŸ¤– GPT ì‘ë‹µ: {response_text}")

            # 3. JSON ë³€í™˜
            try:
                if '```json' in response_text:
                    response_text = response_text.split('```json')[1].split('```')[0].strip()

                parsed_response = json.loads(response_text)
                extracted_line_name = parsed_response.get("line", "").strip()
                extracted_brands = parsed_response.get("brands", [])

                # 4. ê³„ì—´ ID ì°¾ê¸°
                line_id = line_mapping.get(extracted_line_name)
                if not line_id:
                    raise ValueError(f"âŒ '{extracted_line_name}' ê³„ì—´ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

                logger.info(f"âœ… ê³„ì—´ ID: {line_id}, ë¸Œëœë“œ: {extracted_brands}")

                return {
                    "line_id": line_id,
                    "brands": extracted_brands
                }

            except json.JSONDecodeError as e:
                logger.error(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                logger.error(f"ğŸ“„ GPT ì‘ë‹µ ì›ë³¸: {response_text}")
                raise ValueError("âŒ JSON íŒŒì‹± ì‹¤íŒ¨")

        except Exception as e:
            logger.error(f"âŒ í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            raise ValueError(f"âŒ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")

    def generate_chat_response(self, user_input: str) -> str:
        """ì¼ë°˜ ëŒ€í™” ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
        try:
            logger.info(f"ğŸ’¬ ëŒ€í™” ì‘ë‹µ ìƒì„± ì‹œì‘ - ì…ë ¥: {user_input}")

            # 1. í”„ë¡¬í”„íŠ¸ ìƒì„±
            template = self.prompt_loader.get_prompt("chat")
            chat_prompt = (
                f"{template['description']}\n"
                f"{template['rules']}\n"
                f"{template['example_prompt']}\n"
                "ë‹¹ì‹ ì€ í–¥ìˆ˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ìš”ì²­ì— ì¹œì ˆí•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.\n"
                "ë‹¨, í–¥ìˆ˜ ì¶”ì²œì€ í•˜ì§€ë§Œ ì¼ë°˜ì ì¸ ì •ë³´ë§Œ ì œê³µí•˜ê³  , ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n\n"
                f"ì‚¬ìš©ì: {user_input}"
            )
            logger.debug(f"ğŸ“ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸:\n{chat_prompt}")

            # 2. GPT ì‘ë‹µ ìš”ì²­
            logger.info("ğŸ¤– GPT ì‘ë‹µ ìš”ì²­")
            response = self.gpt_client.generate_response(chat_prompt)
            
            if not response:
                logger.error("âŒ GPT ì‘ë‹µì´ ë¹„ì–´ìˆìŒ")
                raise ValueError("ì‘ë‹µ ìƒì„± ì‹¤íŒ¨")

            logger.info("âœ… ì‘ë‹µ ìƒì„± ì™„ë£Œ")
            return response.strip()

        except Exception as e:
            logger.error(f"âŒ ëŒ€í™” ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            raise HTTPException(
                status_code=500,
                detail=f"ëŒ€í™” ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}"
        )

    def generate_recommendation_response(self, user_input: str) -> dict:
        """middle noteë¥¼ í¬í•¨í•œ í–¥ìˆ˜ ì¶”ì²œ"""
        try:
            logger.info(f"ğŸ”„ ì¶”ì²œ ì²˜ë¦¬ ì‹œì‘ - ì…ë ¥: {user_input}")

            # 1. í‚¤ì›Œë“œ ì¶”ì¶œ 
            logger.info("ğŸ” í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œì‘")
            extracted_data = self.extract_keywords_from_input(user_input)
            line_id = extracted_data["line_id"]
            brand_filters = extracted_data["brands"]
            logger.info(f"âœ… ì¶”ì¶œëœ í‚¤ì›Œë“œ - ê³„ì—´ID: {line_id}, ë¸Œëœë“œ: {brand_filters}")

            # 2. í–¥ë£Œ ID ì¡°íšŒ
            logger.info(f"ğŸ” ê³„ì—´ {line_id}ì˜ í–¥ë£Œ ì¡°íšŒ")
            spice_data = self.db_service.fetch_spices_by_line(line_id)
            spice_ids = [spice["id"] for spice in spice_data]

            if not spice_ids:
                logger.error(f"âŒ ê³„ì—´ {line_id}ì— ëŒ€í•œ í–¥ë£Œ ì—†ìŒ")
                raise HTTPException(status_code=404, detail="í•´ë‹¹ ê³„ì—´ì— ë§ëŠ” í–¥ë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            logger.info(f"âœ… í–¥ë£Œ ID ëª©ë¡: {spice_ids}")

            # 3. í–¥ìˆ˜ í•„í„°ë§
            logger.info("ğŸ” í–¥ìˆ˜ í•„í„°ë§ ì‹œì‘")
            filtered_perfumes = self.db_service.get_perfumes_by_middle_notes(spice_ids)
            logger.debug(f"ğŸ“‹ ë¯¸ë“¤ë…¸íŠ¸ ê¸°ì¤€ í•„í„°ë§: {len(filtered_perfumes)}ê°œ")

            if brand_filters:
                filtered_perfumes = [p for p in filtered_perfumes if p["brand"] in brand_filters]
                logger.debug(f"ğŸ“‹ ë¸Œëœë“œ í•„í„°ë§ í›„: {len(filtered_perfumes)}ê°œ")

            if not filtered_perfumes:
                logger.error("âŒ í•„í„°ë§ ê²°ê³¼ ì—†ìŒ")
                raise HTTPException(status_code=404, detail="ì¡°ê±´ì— ë§ëŠ” í–¥ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            # 4. GPT í”„ë¡¬í”„íŠ¸ ìƒì„±
            products_text = "\n".join([
                f"{p['id']}. {p['name_kr']} ({p['brand']}): {p.get('main_accord', 'í–¥ ì •ë³´ ì—†ìŒ')}"
                for p in filtered_perfumes[:50]  # ìµœëŒ€ 50ê°œë¡œ ì œí•œ
            ])

            template = self.prompt_loader.get_prompt("recommendation")
            names_prompt = (
                f"{template['description']}\n"
                f"{template['rules']}"
                f"ì‚¬ìš©ì ìš”ì²­: {user_input}\n"
                f"ì¶”ì¶œëœ í‚¤ì›Œë“œ: {products_text}\n"
                f"í–¥ìˆ˜ì˜ ë¸Œëœë“œ ì´ë¦„ì€ ë“¤ì–´ê°€ì§€ ì•Šì€ ì´ë¦„ë§Œ ìµœëŒ€ 3ê°œ ì¶”ì²œí•´ì£¼ì„¸ìš”.\n\n"
                f"- content: ì¶”ì²œ ì´ìœ ì™€ ì‚¬ìš© ìƒí™©ê³¼ í–¥ìˆ˜ë“¤ì˜ ê³µí†µì ì¸ ëŠë‚Œ í•¨ê»˜ ì ì–´ì£¼ì„¸ìš”.\n\n"
                "ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:\n"
                "```json\n"
                "{\n"
                '  "recommendations": [\n'
                '    {\n'
                '      "name": "ë¸”ë‘ì‰¬ ì˜¤ ë“œ í¼í“¸",\n'
                '      "reason": "ê¹¨ë—í•œ ë¨¸ìŠ¤í¬ì™€ ì€ì€í•œ ë°±í•©ì´ ì–´ìš°ëŸ¬ì ¸, ê°“ ì„¸íƒí•œ ìƒˆí•˜ì–€ ë¦¬ë„¨ì²˜ëŸ¼ ë¶€ë“œëŸ½ê³  ì‹ ì„ í•œ ëŠë‚Œì„ ì„ ì‚¬. í”¼ë¶€ì— ë°€ì°©ë˜ëŠ” ë“¯í•œ ê°€ë²¼ìš´ í–¥ì´ ì˜¤ë˜ ì§€ì†ë˜ë©°, ìì—°ìŠ¤ëŸ½ê³  ë‹¨ì •í•œ ë¶„ìœ„ê¸°ë¥¼ ì—°ì¶œí•¨.",\n'
                '      "situation": "ì•„ì¹¨ ìƒ¤ì›Œ í›„ ìƒì¾Œí•œ ê¸°ë¶„ì„ ìœ ì§€í•˜ê³  ì‹¶ì„ ë•Œ, ì˜¤í”¼ìŠ¤ì—ì„œ ë‹¨ì •í•˜ë©´ì„œë„ ì€ì€í•œ ì¡´ì¬ê°ì„ ë‚¨ê¸°ê³  ì‹¶ì„ ë•Œ"\n'
                '    },\n'
                '    {\n'
                '      "name": "ì‹¤ë²„ ë§ˆìš´í‹´ ì›Œí„° ì˜¤ ë“œ í¼í“¸",\n'
                '      "reason": "ìƒí¼í•œ ì‹œíŠ¸ëŸ¬ìŠ¤ì™€ ì‹ ì„ í•œ ê·¸ë¦° í‹° ë…¸íŠ¸ê°€ ì¡°í™”ë¥¼ ì´ë£¨ë©°, ì•Œí”„ìŠ¤ì˜ ê¹¨ë—í•œ ìƒ˜ë¬¼ì„ ì—°ìƒì‹œí‚¤ëŠ” ë§‘ê³  ì²­ëŸ‰í•œ ëŠë‚Œì„ ì¤Œ. ìš°ë””í•œ ë² ì´ìŠ¤ê°€ ì”ì”í•˜ê²Œ ë‚¨ì•„ ì°¨ë¶„í•œ ë§¤ë ¥ì„ ë”í•¨.",\n'
                '      "situation": "ìš´ë™ í›„ ë•€ì„ ì”»ì–´ë‚´ê³  ê°œìš´í•œ ëŠë‚Œì„ ìœ ì§€í•˜ê³  ì‹¶ì„ ë•Œ, ë”ìš´ ì—¬ë¦„ë‚  ì‹œì›í•˜ê³  ê¹¨ë—í•œ ì¸ìƒì„ ì£¼ê³  ì‹¶ì„ ë•Œ"\n'
                '    },\n'
                '    {\n'
                '      "name": "ì¬ì¦ˆ í´ëŸ½ ì˜¤ ë“œ ëšœì™ˆë ›",\n'
                '      "reason": "ë‹¬ì½¤í•œ ëŸ¼ê³¼ ë¶€ë“œëŸ¬ìš´ ë°”ë‹ë¼ê°€ íƒ€ë°”ì½”ì˜ ìŠ¤ëª¨í‚¤í•¨ê³¼ ì–´ìš°ëŸ¬ì ¸, í´ë˜ì‹í•œ ì¬ì¦ˆ ë°”ì—ì„œ ì˜¤ë˜ëœ ê°€ì£½ ì†ŒíŒŒì— ì•‰ì•„ ì¹µí…Œì¼ì„ ë§ˆì‹œëŠ” ë“¯í•œ ë¶„ìœ„ê¸°ë¥¼ ì—°ì¶œ. ê¹Šê³  ë”°ëœ»í•œ í–¥ì´ ê°ê°ì ì¸ ë¬´ë“œë¥¼ ë”í•¨.",\n'
                '      "situation": "ì—¬ìœ ë¡œìš´ ì €ë… ì‹œê°„, ì¹µí…Œì¼ ë°”ë‚˜ ì¡°ìš©í•œ ë¼ìš´ì§€ì—ì„œ ì„¸ë ¨ëœ ë¶„ìœ„ê¸°ë¥¼ ì—°ì¶œí•˜ê³  ì‹¶ì„ ë•Œ, ê°€ì„ê³¼ ê²¨ìš¸ì²  ë”°ëœ»í•˜ê³  ë§¤í˜¹ì ì¸ í–¥ì„ ì›í•  ë•Œ"\n'
                '    }\n'
                '  ],\n'
                '  "content": "ê¹¨ë—í•œ ë¦¬ë„¨ì˜ ì‚°ëœ»í•¨, ì‹ ì„ í•œ ìì—°ì˜ ì²­ëŸ‰ê°, ê·¸ë¦¬ê³  ë¶€ë“œëŸ¬ìš´ ë”°ëœ»í•¨ì´ ì¡°í™”ë¡­ê²Œ ì–´ìš°ëŸ¬ì§„ ì„¸ë ¨ë˜ê³  ê°ê°ì ì¸ í–¥ì…ë‹ˆë‹¤."'
                '}\n'
                "```"
            )

            try:
                logger.info("ğŸ”„ í–¥ìˆ˜ ì¶”ì²œ ì²˜ë¦¬ ì‹œì‘")
                
                # 1. GPT ì‘ë‹µ ë°›ê¸°
                logger.info("ğŸ¤– GPT ì‘ë‹µ ìš”ì²­")
                response_text = self.gpt_client.generate_response(names_prompt)
                logger.debug(f"ğŸ“ GPT ì›ë³¸ ì‘ë‹µ:\n{response_text}")

                # 2. JSON íŒŒì‹±
                try:
                    # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
                    if '```' in response_text:
                        parts = response_text.split('```')
                        for part in parts:
                            if '{' in part and '}' in part:
                                response_text = part.strip()
                                if response_text.startswith('json'):
                                    response_text = response_text[4:].strip()
                                break

                    # JSON êµ¬ì¡° ì¶”ì¶œ
                    start_idx = response_text.find('{')
                    end_idx = response_text.rfind('}') + 1
                    if (start_idx == -1 or end_idx <= start_idx):
                        raise ValueError("JSON êµ¬ì¡°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                        
                    json_str = response_text[start_idx:end_idx]
                    logger.debug(f"ğŸ“‹ ì¶”ì¶œëœ JSON:\n{json_str}")
                    
                    gpt_response = json.loads(json_str)
                    logger.info("âœ… JSON íŒŒì‹± ì„±ê³µ")

                except json.JSONDecodeError as e:
                    logger.error(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                    logger.error(f"ğŸ“„ íŒŒì‹± ì‹œë„í•œ í…ìŠ¤íŠ¸:\n{json_str if 'json_str' in locals() else 'None'}")
                    raise ValueError("JSON íŒŒì‹± ì‹¤íŒ¨")

                # 3. ì¶”ì²œ ëª©ë¡ ìƒì„±
                recommendations = []
                for rec in gpt_response.get("recommendations", []):
                    matched_perfume = next(
                        (p for p in filtered_perfumes if p["name_kr"] == rec["name"]), 
                        None
                    )

                    if matched_perfume:
                        recommendations.append({
                            "id": matched_perfume["id"],
                            "name": matched_perfume["name_kr"], 
                            "brand": matched_perfume["brand"],
                            "reason": rec.get("reason", "ì¶”ì²œ ì´ìœ  ì—†ìŒ"),
                            "situation": rec.get("situation", "ì‚¬ìš© ìƒí™© ì—†ìŒ")
                        })

                if not recommendations:
                    logger.error("âŒ ìœ íš¨í•œ ì¶”ì²œ ê²°ê³¼ ì—†ìŒ")
                    raise ValueError("ìœ íš¨í•œ ì¶”ì²œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")

                # 4. ê³µí†µ line_id ì°¾ê¸°
                common_line_id = self.get_common_line_id(recommendations)
                logger.info(f"âœ… ê³µí†µ ê³„ì—´ ID: {common_line_id}")

                return {
                    "recommendations": recommendations,
                    "content": gpt_response.get("content", "ì¶”ì²œ ë¶„ì„ ì‹¤íŒ¨"),
                    "line_id": common_line_id
                }

            except ValueError as ve:
                logger.error(f"âŒ ì¶”ì²œ ì²˜ë¦¬ ì˜¤ë¥˜: {ve}")
                raise HTTPException(status_code=400, detail=str(ve))
            except Exception as e:
                logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
                raise HTTPException(status_code=500, detail="ì¶”ì²œ ìƒì„± ì‹¤íŒ¨")

        except json.JSONDecodeError as e:
            logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            raise HTTPException(status_code=500, detail="ì¶”ì²œ JSON íŒŒì‹± ì‹¤íŒ¨")
        except Exception as e:
            logger.error(f"ì¶”ì²œ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            raise HTTPException(status_code=500, detail="ì¶”ì²œ ìƒì„± ì‹¤íŒ¨")

    def get_common_line_id(self, recommendations: list) -> int:
        """ì¶”ì²œëœ productë“¤ì˜ ê³µí†µ ê³„ì—´ IDë¥¼ ì°¾ëŠ” í•¨ìˆ˜"""
        try:
                logger.info("ğŸ” GPTë¥¼ ì´ìš©í•œ ê³µí†µ ê³„ì—´ ID ê²€ìƒ‰ ì‹œì‘")

                if not recommendations:
                    logger.warning("âš ï¸ ì¶”ì²œ ëª©ë¡ì´ ë¹„ì–´ ìˆìŒ") 
                    return 1

                # 1. DBì—ì„œ line ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                line_data = self.db_service.fetch_line_data()
                if not line_data:
                    logger.error("âŒ ê³„ì—´ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    return 1
                    
                # product ê³„ì—´ ì •ë³´ ìƒì„±
                line_info = "\n".join([
                    f"{line['id']}: {line['name']} - {line.get('content', 'ì„¤ëª… ì—†ìŒ')}"
                    for line in line_data
                ])

                # 2. product ëª©ë¡ ìƒì„±
                product_list = "\n".join([
                    f"{rec['id']}. {rec['name']}: {rec['reason']}" 
                    for rec in recommendations
                ])
                logger.debug(f"ğŸ“‹ ë¶„ì„í•  product ëª©ë¡: {product_list}")

                # 3. GPT í”„ë¡¬í”„íŠ¸ ìƒì„± 
                prompt = (
                    f"ë‹¤ìŒ í–¥ìˆ˜/ë””í“¨ì € ëª©ë¡ì„ ë³´ê³  ê°€ì¥ ì í•©í•œ ê³„ì—´ IDë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.\n\n"
                    f"í–¥ìˆ˜/ë””í“¨ì € ëª©ë¡:\n{product_list}\n\n"
                    f"ê³„ì—´ ì •ë³´:\n{line_info}\n\n"
                    "ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:\n"
                    "{\n"
                    '  "line_id": ì„ íƒí•œ_ID\n'
                    "}"
                )

                # 4. GPT ìš”ì²­
                logger.info("ğŸ¤– GPT ì‘ë‹µ ìš”ì²­") 
                response = self.gpt_client.generate_response(prompt)
                logger.debug(f"ğŸ“ GPT ì‘ë‹µ:\n{response}")

                # 5. JSON íŒŒì‹± ë° ê²€ì¦
                try:
                    clean_response = response.strip()
                    
                    # ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ ì œê±°
                    if '```' in clean_response:
                        parts = clean_response.split('```')
                        for part in parts:
                            if '{' in part and '}' in part:
                                clean_response = part.strip()
                                if clean_response.startswith('json'):
                                    clean_response = clean_response[4:].strip()
                                break

                    # JSON ì¶”ì¶œ
                    json_str = clean_response[
                        clean_response.find('{'):
                        clean_response.rfind('}')+1
                    ]
                    
                    response_data = json.loads(json_str)
                    line_id = response_data.get('line_id')

                    # line_id ê²€ì¦
                    valid_ids = {line['id'] for line in line_data}
                    if not isinstance(line_id, int) or line_id not in valid_ids:
                        raise ValueError(f"ìœ íš¨í•˜ì§€ ì•Šì€ line_id: {line_id}")

                    logger.info(f"âœ… ê³µí†µ ê³„ì—´ ID ì°¾ìŒ: {line_id}")
                    return line_id

                except (json.JSONDecodeError, ValueError) as e:
                    logger.error(f"âŒ JSON íŒŒì‹±/ê²€ì¦ ì˜¤ë¥˜: {e}")
                    return 1

        except Exception as e:
            logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return 1
        
    def fashion_based_generate_recommendation_response(self, user_input: str, image_caption: str) -> dict:
        """middle noteë¥¼ í¬í•¨í•œ í–¥ìˆ˜ ì¶”ì²œ"""
        try:
            logger.info(f"ğŸ”„ ì¶”ì²œ ì²˜ë¦¬ ì‹œì‘ - ì…ë ¥: {user_input}")

            # 1. í‚¤ì›Œë“œ ì¶”ì¶œ 
            logger.info("ğŸ” í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œì‘")
            extracted_data = self.extract_keywords_from_input(user_input, image_caption)
            line_id = extracted_data["line_id"]
            brand_filters = extracted_data["brands"]
            logger.info(f"âœ… ì¶”ì¶œëœ í‚¤ì›Œë“œ - ê³„ì—´ID: {line_id}, ë¸Œëœë“œ: {brand_filters}")

            # 2. í–¥ë£Œ ID ì¡°íšŒ
            logger.info(f"ğŸ” ê³„ì—´ {line_id}ì˜ í–¥ë£Œ ì¡°íšŒ")
            spice_data = self.db_service.fetch_spices_by_line(line_id)
            spice_ids = [spice["id"] for spice in spice_data]

            if not spice_ids:
                logger.error(f"âŒ ê³„ì—´ {line_id}ì— ëŒ€í•œ í–¥ë£Œ ì—†ìŒ")
                raise HTTPException(status_code=404, detail="í•´ë‹¹ ê³„ì—´ì— ë§ëŠ” í–¥ë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            logger.info(f"âœ… í–¥ë£Œ ID ëª©ë¡: {spice_ids}")

            # 3. í–¥ìˆ˜ í•„í„°ë§
            logger.info("ğŸ” í–¥ìˆ˜ í•„í„°ë§ ì‹œì‘")
            filtered_perfumes = self.db_service.get_perfumes_by_middle_notes(spice_ids)
            logger.debug(f"ğŸ“‹ ë¯¸ë“¤ë…¸íŠ¸ ê¸°ì¤€ í•„í„°ë§: {len(filtered_perfumes)}ê°œ")

            if brand_filters:
                filtered_perfumes = [p for p in filtered_perfumes if p["brand"] in brand_filters]
                logger.debug(f"ğŸ“‹ ë¸Œëœë“œ í•„í„°ë§ í›„: {len(filtered_perfumes)}ê°œ")

            if not filtered_perfumes:
                logger.error("âŒ í•„í„°ë§ ê²°ê³¼ ì—†ìŒ")
                raise HTTPException(status_code=404, detail="ì¡°ê±´ì— ë§ëŠ” í–¥ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            # 4. GPT í”„ë¡¬í”„íŠ¸ ìƒì„±
            products_text = "\n".join([
                f"{p['id']}. {p['name_kr']} ({p['brand']}): {p.get('main_accord', 'í–¥ ì •ë³´ ì—†ìŒ')}"
                for p in filtered_perfumes[:30]  # ìµœëŒ€ 10ê°œë¡œ ì œí•œ
            ])

            template = self.prompt_loader.get_prompt("recommendation")
            names_prompt = (
                f"{template['description']}\n"
                f"{template['rules']}\n"
                f"### user_input: {user_input}\n\n"
                f"### image_caption: {image_caption}\n\n"
                f"### Extracted keywords: {products_text}\n"
                f"Recommend up to 3 perfume names without including the brand names.\n\n"
                f"Note: The recommendations should refer to the user_input, image_caption, and extracted keywords. The image_caption describes the person's outfit, and the recommended perfumes should match the described outfit.\n"
                f"- content: Please include the reason for the recommendation, the situation it suits, and the common feel of the perfumes.\n\n"
                "Please respond only in the following JSON format:\n"
                "```json\n"
                "{\n"
                '  "recommendations": [\n'
                '    {\n'
                '      "name": "ë¸”ë‘ì‰¬ ì˜¤ ë“œ í¼í“¸",\n'
                '      "reason": "ê¹¨ë—í•œ ë¨¸ìŠ¤í¬ì™€ ì€ì€í•œ ë°±í•©ì´ ì–´ìš°ëŸ¬ì ¸, ë§ˆì¹˜ ìƒˆí•˜ì–€ ì…”ì¸ ë¥¼ ê°“ ë‹¤ë¦° ë“¯í•œ ê¹”ë”í•˜ê³  ì„¸ë ¨ëœ ëŠë‚Œì„ ì„ ì‚¬í•©ë‹ˆë‹¤. ìì—°ìŠ¤ëŸ½ê³  ìš°ì•„í•œ ìŠ¤íƒ€ì¼ì„ ì—°ì¶œí•˜ëŠ” ë° ì–´ìš¸ë¦¬ëŠ” í–¥ì…ë‹ˆë‹¤.",\n'
                '      "situation": "ë¯¸ë‹ˆë©€í•œ í™”ì´íŠ¸ ì…”ì¸ ì™€ ìŠ¬ë™ìŠ¤ ì¡°í•©ìœ¼ë¡œ ì„¸ë ¨ëœ ì˜¤í”¼ìŠ¤ë£©ì„ ì—°ì¶œí•  ë•Œ, ì‹¬í”Œí•˜ë©´ì„œë„ ê³ ê¸‰ìŠ¤ëŸ¬ìš´ ë¬´ë“œë¥¼ ë”í•˜ê³  ì‹¶ì„ ë•Œ"\n'
                '    },\n'
                '    {\n'
                '      "name": "ì‹¤ë²„ ë§ˆìš´í‹´ ì›Œí„° ì˜¤ ë“œ í¼í“¸",\n'
                '      "reason": "ìƒí¼í•œ ì‹œíŠ¸ëŸ¬ìŠ¤ì™€ ì‹ ì„ í•œ ê·¸ë¦° í‹° ë…¸íŠ¸ê°€ ì¡°í™”ë¥¼ ì´ë£¨ë©°, í•œì—¬ë¦„ì— ê°€ë²¼ìš´ ë¦¬ë„¨ ì…”ì¸ ë¥¼ ì…ì€ ë“¯í•œ ì‹œì›í•˜ê³  ì¾Œì í•œ ëŠë‚Œì„ ì¤ë‹ˆë‹¤. ëª¨ë˜í•˜ë©´ì„œë„ í™œë™ì ì¸ ìŠ¤íƒ€ì¼ì„ ì—°ì¶œí•˜ëŠ” ë° ì í•©í•©ë‹ˆë‹¤.",\n'
                '      "situation": "ìºì£¼ì–¼í•œ ë¦¬ë„¨ ì…”ì¸ ì™€ ë°ë‹˜ì„ ë§¤ì¹˜í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê³  ì—¬ìœ ë¡œìš´ ë¶„ìœ„ê¸°ë¥¼ ì—°ì¶œí•  ë•Œ, ì—¬ë¦„ì²  ì‹œì›í•˜ê³  ì²­ëŸ‰í•œ ì´ë¯¸ì§€ë¥¼ ê°•ì¡°í•˜ê³  ì‹¶ì„ ë•Œ"\n'
                '    },\n'
                '    {\n'
                '      "name": "ì¬ì¦ˆ í´ëŸ½ ì˜¤ ë“œ ëšœì™ˆë ›",\n'
                '      "reason": "ë‹¬ì½¤í•œ ëŸ¼ê³¼ ë¶€ë“œëŸ¬ìš´ ë°”ë‹ë¼ê°€ íƒ€ë°”ì½”ì˜ ìŠ¤ëª¨í‚¤í•¨ê³¼ ì–´ìš°ëŸ¬ì ¸, ë¹ˆí‹°ì§€í•œ ê°€ì£½ ì¬í‚·ê³¼ í´ë˜ì‹í•œ ë¡œí¼ë¥¼ ë§¤ì¹˜í•œ ë“¯í•œ ê°ê°ì ì¸ ë¬´ë“œë¥¼ ì™„ì„±í•©ë‹ˆë‹¤. ìš°ì•„í•˜ë©´ì„œë„ ê°œì„± ìˆëŠ” ìŠ¤íƒ€ì¼ì„ ì—°ì¶œí•˜ê¸°ì— ì í•©í•©ë‹ˆë‹¤.",\n'
                '      "situation": "ê°€ì£½ ì¬í‚·ê³¼ ì²¼ì‹œ ë¶€ì¸ ë¥¼ ë§¤ì¹˜í•˜ì—¬ ì„¸ë ¨ëœ ë‚¨ì„±ë¯¸ë¥¼ ê°•ì¡°í•  ë•Œ, í´ë˜ì‹í•œ íŠ¸ë Œì¹˜ì½”íŠ¸ë‚˜ ë‹ˆíŠ¸ì›¨ì–´ì™€ í•¨ê»˜ ë¶„ìœ„ê¸° ìˆëŠ” ê°€ì„, ê²¨ìš¸ ë£©ì„ ì™„ì„±í•˜ê³  ì‹¶ì„ ë•Œ"\n'
                '    }\n'
                '  ],\n'
                '  "content": "ê¹¨ë—í•œ ë¦¬ë„¨ì˜ ì‚°ëœ»í•¨, ì‹ ì„ í•œ ìì—°ì˜ ì²­ëŸ‰ê°, ê·¸ë¦¬ê³  ë¶€ë“œëŸ¬ìš´ ë”°ëœ»í•¨ì´ ì¡°í™”ë¡­ê²Œ ì–´ìš°ëŸ¬ì§„ ì„¸ë ¨ë˜ê³  ê°ê°ì ì¸ í–¥ì…ë‹ˆë‹¤."'
                '}\n'
                "```"
            )

            try:
                logger.info("ğŸ”„ í–¥ìˆ˜ ì¶”ì²œ ì²˜ë¦¬ ì‹œì‘")
                
                # 1. GPT ì‘ë‹µ ë°›ê¸°
                logger.info("ğŸ¤– GPT ì‘ë‹µ ìš”ì²­")
                response_text = self.gpt_client.generate_response(names_prompt)
                logger.debug(f"ğŸ“ GPT ì›ë³¸ ì‘ë‹µ:\n{response_text}")

                # 2. JSON íŒŒì‹±
                try:
                    # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
                    if '```' in response_text:
                        parts = response_text.split('```')
                        for part in parts:
                            if '{' in part and '}' in part:
                                response_text = part.strip()
                                if response_text.startswith('json'):
                                    response_text = response_text[4:].strip()
                                break

                    # JSON êµ¬ì¡° ì¶”ì¶œ
                    start_idx = response_text.find('{')
                    end_idx = response_text.rfind('}') + 1
                    if (start_idx == -1 or end_idx <= start_idx):
                        raise ValueError("JSON êµ¬ì¡°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                        
                    json_str = response_text[start_idx:end_idx]
                    logger.debug(f"ğŸ“‹ ì¶”ì¶œëœ JSON:\n{json_str}")
                    
                    gpt_response = json.loads(json_str)
                    logger.info("âœ… JSON íŒŒì‹± ì„±ê³µ")

                except json.JSONDecodeError as e:
                    logger.error(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                    logger.error(f"ğŸ“„ íŒŒì‹± ì‹œë„í•œ í…ìŠ¤íŠ¸:\n{json_str if 'json_str' in locals() else 'None'}")
                    raise ValueError("JSON íŒŒì‹± ì‹¤íŒ¨")

                # 3. ì¶”ì²œ ëª©ë¡ ìƒì„±
                recommendations = []
                for rec in gpt_response.get("recommendations", []):
                    matched_perfume = next(
                        (p for p in filtered_perfumes if p["name_kr"] == rec["name"]), 
                        None
                    )

                    if matched_perfume:
                        recommendations.append({
                            "id": matched_perfume["id"],
                            "name": matched_perfume["name_kr"], 
                            "brand": matched_perfume["brand"],
                            "reason": rec.get("reason", "ì¶”ì²œ ì´ìœ  ì—†ìŒ"),
                            "situation": rec.get("situation", "ì‚¬ìš© ìƒí™© ì—†ìŒ")
                        })

                if not recommendations:
                    logger.error("âŒ ìœ íš¨í•œ ì¶”ì²œ ê²°ê³¼ ì—†ìŒ")
                    raise ValueError("ìœ íš¨í•œ ì¶”ì²œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")

                # 4. ê³µí†µ line_id ì°¾ê¸°
                common_line_id = self.get_common_line_id(recommendations)
                logger.info(f"âœ… ê³µí†µ ê³„ì—´ ID: {common_line_id}")

                return {
                    "recommendations": recommendations,
                    "content": gpt_response.get("content", "ì¶”ì²œ ë¶„ì„ ì‹¤íŒ¨"),
                    "line_id": common_line_id
                }

            except ValueError as ve:
                logger.error(f"âŒ ì¶”ì²œ ì²˜ë¦¬ ì˜¤ë¥˜: {ve}")
                raise HTTPException(status_code=400, detail=str(ve))
            except Exception as e:
                logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
                raise HTTPException(status_code=500, detail="ì¶”ì²œ ìƒì„± ì‹¤íŒ¨")

        except json.JSONDecodeError as e:
            logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            raise HTTPException(status_code=500, detail="ì¶”ì²œ JSON íŒŒì‹± ì‹¤íŒ¨")
        except Exception as e:
            logger.error(f"ì¶”ì²œ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            raise HTTPException(status_code=500, detail="ì¶”ì²œ ìƒì„± ì‹¤íŒ¨")    

    def initialize_vector_db(self, diffuser_data, diffuser_scent_descriptions):
        """Initialize Chroma DB and store embeddings."""
        logger.info(f"Initializing Chroma DB.")
        collection = chroma_client.get_or_create_collection(name="embeddings", embedding_function=embedding_function)

        # Fetch existing IDs from the collection
        existing_ids = set()
        try:
            results = collection.get()
            existing_ids.update(results["ids"])
        except Exception as e:
            logger.error(f"Error fetching existing IDs: {e}")

        # Insert vectors for each diffuser if not already in collection
        for diffuser in diffuser_data:
            if str(diffuser["id"]) in existing_ids:
                # logger.info(f"Skipping diffuser ID {diffuser['id']} (already in collection).")
                continue
            
            logger.info(f"Inserting vectors for ID {diffuser['id']}.")
            scent_description = diffuser_scent_descriptions.get(diffuser["id"], "")

            combined_text = f"{diffuser['brand']}\n{diffuser['name_kr']} ({diffuser['name_en']})\n{scent_description}"

            # Store in Chroma
            collection.add(
                documents=[combined_text],
                metadatas=[{"id": diffuser["id"], "name_kr": diffuser["name_kr"], "brand": diffuser["brand"], "category_id": diffuser["category_id"], "scent_description": scent_description}],
                ids=[str(diffuser["id"])]
            )
        logger.info(f"Diffuser data have been embedded and stored in Chroma.")

        return collection
    
    def get_distinct_brands(self, product_data):
        """Return all distinct diffuser brands from the product data."""
        # ë””í“¨ì €ëŠ” ê°œìˆ˜ê°€ ì ìœ¼ë¯€ë¡œ ë””í“¨ì € ë°ì´í„°ë§Œ ê°€ì§€ê³  ë¸Œëœë“œ ì¶”ì¶œí•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ ë”°ë¡œ ìƒì„±
        brands = set()
        for product in product_data:
            brands.add(product.get("brand", "Unknown"))
        return brands
    
    def get_fragrance_recommendation(self, user_input, caption):
        # GPTì—ê²Œ user inputê³¼ caption ì „ë‹¬ í›„ ì–´ìš¸ë¦¬ëŠ” í–¥ì— ëŒ€í•œ ì„¤ëª… í•œêµ­ì–´ë¡œ ë°˜í™˜(íŠ¹ì • ë¸Œëœë“œ ìˆìœ¼ë©´ ë§¨ ì•ì— ì ê²Œë” ìš”ì²­.)
        existing_brands = self.get_distinct_brands(self.all_diffusers)
        brands_str = ", ".join(existing_brands)

        fragrance_description_prompt = f"""You are a fragrance expert with in-depth knowledge of various scents. Based on the User Input and Image Caption, **imagine** and provide a fragrance scent description that matches the room's description and the user's request. Focus more on the User Input. Your task is to creatively describe a fragrance that would fit well with the mood and characteristics of the room as described in the caption, as well as the user's scent preference. Do not mention specific diffuser or perfume products.

### Instructions:
- Existing Brands: {brands_str}
1. **If a specific brand is mentioned**, check if it exists in the list of existing brands above. If it does, acknowledge the brand name without referring to any specific product and describe a fitting scent that aligns with the user's request.  
**IF THE BRAND IS MENTIONED IN THE USER INPUT BUT IS NOT FOUND IN THE EXISTING BRANDS LIST, START BY 'Not Found' TO SAY THE BRAND DOES NOT EXIST.**
2. **If the brand is misspelled or doesn't exist**, please:
    - Correct the spelling if the brand is close to an existing brand (e.g., "ì•„ì¿ ì•„ íŒŒë¥´ë§ˆ" -> "ì•„ì¿ ì•„ ë”” íŒŒë¥´ë§ˆ").
    - **IF THE BRAND IS MENTIONED IN THE USER INPUT BUT IS NOT FOUND IN THE EXISTING BRANDS LIST, START BY 'Not Found' TO SAY THE BRAND DOES NOT EXIST.** Then, recommend a suitable fragrance based on the context and preferences described in the user input.
3. Provide the fragrance description in **Korean**, focusing on key scent notes and creative details that align with the mood and characteristics described in the user input and image caption. Do **not mention specific diffuser or perfume products.**

### Example Responses:

#### Example 1 (when a brand is mentioned, but with a minor spelling error):
- User Input: ì•„ì¿ ì•„ íŒŒë¥´ë§ˆì˜ ìš°ë””í•œ ë² ì´ìŠ¤ë¥¼ ê°€ì§„ ë””í“¨ì €ë¥¼ ì¶”ì²œí•´ì¤˜.
- Image Caption: The image shows a modern living room with a large window on the right side. The room has white walls and wooden flooring. On the left side of the room, there is a gray sofa and a white coffee table with a black and white patterned rug in front of it. In the center of the image, there are six black chairs arranged around a wooden dining table. The table is set with a vase and other decorative objects on it. Above the table, two large windows let in natural light and provide a view of the city outside. A white floor lamp is placed on the floor next to the sofa.
- Response:
Brand: ì•„ì¿ ì•„ ë”” íŒŒë¥´ë§ˆ
Scent Description: ìš°ë””í•œ ë² ì´ìŠ¤ì— ë”°ëœ»í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë¶„ìœ„ê¸°ë¥¼ ë”í•˜ëŠ” í–¥ì´ ì–´ìš¸ë¦½ë‹ˆë‹¤. ì€ì€í•œ ìƒŒë“¤ìš°ë“œì™€ ë¶€ë“œëŸ¬ìš´ ì‹œë”ìš°ë“œê°€ ì¡°í™”ë¥¼ ì´ë£¨ë©°, ê°€ë²¼ìš´ ë¨¸ìŠ¤í¬ì™€ ë“œë¼ì´í•œ ë² í‹°ë²„ê°€ ê¹Šì´ë¥¼ ë”í•©ë‹ˆë‹¤. ê°€ë²¼ìš´ í—ˆë¸Œì™€ ìƒì¾Œí•œ ì‹œíŠ¸ëŸ¬ìŠ¤ ë…¸íŠ¸ê°€ ì€ì€í•˜ê²Œ ê· í˜•ì„ ì´ë£¨ë©° ì—¬ìœ ë¡­ê³  ì„¸ë ¨ëœ ë¶„ìœ„ê¸°ë¥¼ ì—°ì¶œí•©ë‹ˆë‹¤.

#### Example 2 (when no brand is mentioned):
- User Input: ìš°ë””í•œ ë² ì´ìŠ¤ë¥¼ ê°€ì§„ ë””í“¨ì €ë¥¼ ì¶”ì²œí•´ì¤˜.
- Image Caption: The image shows a modern living room with a large window on the right side. The room has white walls and wooden flooring. On the left side of the room, there is a gray sofa and a white coffee table with a black and white patterned rug in front of it. In the center of the image, there are six black chairs arranged around a wooden dining table. The table is set with a vase and other decorative objects on it. Above the table, two large windows let in natural light and provide a view of the city outside. A white floor lamp is placed on the floor next to the sofa.
- Response:
Brand: None
Scent Description: ìš°ë””í•œ ë² ì´ìŠ¤ì— ë”°ëœ»í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë¶„ìœ„ê¸°ë¥¼ ë”í•˜ëŠ” í–¥ì´ ì–´ìš¸ë¦½ë‹ˆë‹¤. ì€ì€í•œ ìƒŒë“¤ìš°ë“œì™€ ë¶€ë“œëŸ¬ìš´ ì‹œë”ìš°ë“œê°€ ì¡°í™”ë¥¼ ì´ë£¨ë©°, ê°€ë²¼ìš´ ë¨¸ìŠ¤í¬ì™€ ë“œë¼ì´í•œ ë² í‹°ë²„ê°€ ê¹Šì´ë¥¼ ë”í•©ë‹ˆë‹¤. ê°€ë²¼ìš´ í—ˆë¸Œì™€ ìƒì¾Œí•œ ì‹œíŠ¸ëŸ¬ìŠ¤ ë…¸íŠ¸ê°€ ì€ì€í•˜ê²Œ ê· í˜•ì„ ì´ë£¨ë©° ì—¬ìœ ë¡­ê³  ì„¸ë ¨ëœ ë¶„ìœ„ê¸°ë¥¼ ì—°ì¶œí•©ë‹ˆë‹¤.

#### Example 3 (when a brand is mentioned but not in the list of existing brands):
- User Input: ìƒ¤ë„¬ ë¸Œëœë“œ ì œí’ˆì˜ ìš°ë””í•œ ë² ì´ìŠ¤ë¥¼ ê°€ì§„ ë””í“¨ì €ë¥¼ ì¶”ì²œí•´ì¤˜.
- Image Caption: The image shows a modern living room with a large window on the right side. The room has white walls and wooden flooring. On the left side of the room, there is a gray sofa and a white coffee table with a black and white patterned rug in front of it. In the center of the image, there are six black chairs arranged around a wooden dining table. The table is set with a vase and other decorative objects on it. Above the table, two large windows let in natural light and provide a view of the city outside. A white floor lamp is placed on the floor next to the sofa.
- Response:
Brand: Not Found
Scent Description: ìš°ë””í•œ ë² ì´ìŠ¤ì— ë”°ëœ»í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë¶„ìœ„ê¸°ë¥¼ ë”í•˜ëŠ” í–¥ì´ ì–´ìš¸ë¦½ë‹ˆë‹¤. ì€ì€í•œ ìƒŒë“¤ìš°ë“œì™€ ë¶€ë“œëŸ¬ìš´ ì‹œë”ìš°ë“œê°€ ì¡°í™”ë¥¼ ì´ë£¨ë©°, ê°€ë²¼ìš´ ë¨¸ìŠ¤í¬ì™€ ë“œë¼ì´í•œ ë² í‹°ë²„ê°€ ê¹Šì´ë¥¼ ë”í•©ë‹ˆë‹¤. ê°€ë²¼ìš´ í—ˆë¸Œì™€ ìƒì¾Œí•œ ì‹œíŠ¸ëŸ¬ìŠ¤ ë…¸íŠ¸ê°€ ì€ì€í•˜ê²Œ ê· í˜•ì„ ì´ë£¨ë©° ì—¬ìœ ë¡­ê³  ì„¸ë ¨ëœ ë¶„ìœ„ê¸°ë¥¼ ì—°ì¶œí•©ë‹ˆë‹¤.

User Input: {user_input}
Image Caption: {caption}
Response:"""
        
        fragrance_description = self.gpt_client.generate_response(fragrance_description_prompt).strip()
        return fragrance_description
    
    def generate_interior_design_based_recommendation_response(self, user_input: str, image_caption: str) -> dict:
        """ê³µê°„ ì‚¬ì§„ ê¸°ë°˜ ë””í“¨ì € ì¶”ì²œ"""
        try:
            logger.info(f"ğŸ  ê³µê°„ ì‚¬ì§„ ê¸°ë°˜ ë””í“¨ì € ì¶”ì²œ ì‹œì‘: {user_input}")
            fragrance_description = self.get_fragrance_recommendation(user_input, image_caption)

            try:
                diffusers_result = self.collection.query(
                    query_texts=[fragrance_description],
                    n_results=10,
                    # where={"brand": "ë”¥í‹°í¬"},
                    # where_document={"$contains":"í”„ë£¨í‹°"}
                )

                # Extracting data from the query result
                ids = diffusers_result["ids"][0]
                documents = diffusers_result["documents"][0]
                metadata = diffusers_result["metadatas"][0]

                for i in range(len(ids)):
                    product_id = ids[i]
                    name_kr = metadata[i]["name_kr"]
                    brand = metadata[i]["brand"]
                    scent_description = metadata[i]["scent_description"]
                    logger.info(f"Query Result - id: {product_id}. {name_kr} ({brand})\n{scent_description}\n")

                diffusers_text = "\n".join([
                    f"{metadata[i]['id']}. {metadata[i]['name_kr']} ({metadata[i]['brand']}): {metadata[i]['scent_description']}"
                    for i in range(len(metadata))
                ])
            except Exception as e:
                logger.error(f"Error during Chroma query: {e}")
                diffusers_result = None

            template = self.prompt_loader.get_prompt("diffuser_recommendation")
            diffuser_prompt = (
                f"{template['description']}\n"
                f"{template['rules']}\n"
                f"ì‚¬ìš©ìì˜ user_input: {user_input}\n\n"
                f"ì•„ë˜ ì…ë ¥ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•œ í›„ ë””í“¨ì €ë¥¼ ì¶”ì²œí•˜ì„¸ìš”:\n"
                f"{user_input}\n\n"
                f"ë””í“¨ì € ëª©ë¡(id. name (brand): scent_description):\n{diffusers_text}\n"
                f"ë””í“¨ì €ì˜ ë¸Œëœë“œ ì´ë¦„ì€ í¬í•¨í•˜ì§€ ì•Šì€ id,nameë§Œ í¬í•¨í•˜ì—¬ ë””í“¨ì €ë¥¼ 2ê°œ ì¶”ì²œí•´ì£¼ì„¸ìš”.\n\n"
                f"- content: user_inputë¥¼ ë°”íƒ•ìœ¼ë¡œ ë””í“¨ì €ë¥¼ ì¶”ì²œí•œ ì´ìœ ì™€ ì‚¬ìš© ìƒí™©, ë””í“¨ì €ë“¤ì˜ ê³µí†µì ì¸ ëŠë‚Œì„ í•¨ê»˜ ì ì–´ì£¼ì„¸ìš”.\n"
                "ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:\n"
                "```json\n"
                "{\n"
                '  "recommendations": [\n'
                '    {\n'
                '      "id": 1503,\n'
                '      "name": "ë¸”ë‘ì‰¬ ì˜¤ ë“œ í¼í“¸",\n'
                '      "reason": "ê¹¨ë—í•œ ë¨¸ìŠ¤í¬ì™€ ì€ì€í•œ ë°±í•©ì´ ì–´ìš°ëŸ¬ì ¸, ê°“ ì„¸íƒí•œ ìƒˆí•˜ì–€ ë¦¬ë„¨ì²˜ëŸ¼ ë¶€ë“œëŸ½ê³  ì‹ ì„ í•œ ëŠë‚Œì„ ì„ ì‚¬í•©ë‹ˆë‹¤. í”¼ë¶€ì— ë°€ì°©ë˜ëŠ” ë“¯í•œ ê°€ë²¼ìš´ í–¥ì´ ì˜¤ë˜ ì§€ì†ë˜ë©°, ìì—°ìŠ¤ëŸ½ê³  ë‹¨ì •í•œ ë¶„ìœ„ê¸°ë¥¼ ì—°ì¶œí•©ë‹ˆë‹¤.",\n'
                '      "situation": "ì•„ì¹¨ ìƒ¤ì›Œ í›„ ìƒì¾Œí•œ ê¸°ë¶„ì„ ìœ ì§€í•˜ê³  ì‹¶ì„ ë•Œ, ì˜¤í”¼ìŠ¤ì—ì„œ ë‹¨ì •í•˜ë©´ì„œë„ ì€ì€í•œ ì¡´ì¬ê°ì„ ë‚¨ê¸°ê³  ì‹¶ì„ ë•Œ"\n'
                '    },\n'
                '    {\n'
                '      "id": 1478,\n'
                '      "name": "ì‹¤ë²„ ë§ˆìš´í‹´ ì›Œí„° ì˜¤ ë“œ í¼í“¸",\n'
                '      "reason": "ìƒí¼í•œ ì‹œíŠ¸ëŸ¬ìŠ¤ì™€ ì‹ ì„ í•œ ê·¸ë¦° í‹° ë…¸íŠ¸ê°€ ì¡°í™”ë¥¼ ì´ë£¨ë©°, ì•Œí”„ìŠ¤ì˜ ê¹¨ë—í•œ ìƒ˜ë¬¼ì„ ì—°ìƒì‹œí‚¤ëŠ” ë§‘ê³  ì²­ëŸ‰í•œ ëŠë‚Œì„ ì¤ë‹ˆë‹¤. ìš°ë””í•œ ë² ì´ìŠ¤ê°€ ì”ì”í•˜ê²Œ ë‚¨ì•„ ì°¨ë¶„í•œ ë§¤ë ¥ì„ ë”í•©ë‹ˆë‹¤.",\n'
                '      "situation": "ìš´ë™ í›„ ë•€ì„ ì”»ì–´ë‚´ê³  ê°œìš´í•œ ëŠë‚Œì„ ìœ ì§€í•˜ê³  ì‹¶ì„ ë•Œ, ë”ìš´ ì—¬ë¦„ë‚  ì‹œì›í•˜ê³  ê¹¨ë—í•œ ì¸ìƒì„ ì£¼ê³  ì‹¶ì„ ë•Œ"\n'
                '    }\n'
                '  ],\n'
                '  "content": "ê¹¨ë—í•œ ë¦¬ë„¨ì˜ ì‚°ëœ»í•¨, ì‹ ì„ í•œ ìì—°ì˜ ì²­ëŸ‰ê°, ê·¸ë¦¬ê³  ë¶€ë“œëŸ¬ìš´ ë”°ëœ»í•¨ì´ ì¡°í™”ë¡­ê²Œ ì–´ìš°ëŸ¬ì§„ ì„¸ë ¨ë˜ê³  ê°ê°ì ì¸ í–¥ì…ë‹ˆë‹¤."'
                '}\n'
                "```"
            )

            try:
                logger.info("ğŸ”„ ë””í“¨ì € ì¶”ì²œ ì²˜ë¦¬ ì‹œì‘")
                
                # 1. GPT ì‘ë‹µ ë°›ê¸°
                logger.info("ğŸ¤– GPT ì‘ë‹µ ìš”ì²­")
                response_text = self.gpt_client.generate_response(diffuser_prompt)
                logger.debug(f"ğŸ“ GPT ì›ë³¸ ì‘ë‹µ:\n{response_text}")

                # 2. JSON íŒŒì‹±
                try:
                    # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
                    if '```' in response_text:
                        parts = response_text.split('```')
                        for part in parts:
                            if '{' in part and '}' in part:
                                response_text = part.strip()
                                if response_text.startswith('json'):
                                    response_text = response_text[4:].strip()
                                break

                    # JSON êµ¬ì¡° ì¶”ì¶œ
                    start_idx = response_text.find('{')
                    end_idx = response_text.rfind('}') + 1
                    if (start_idx == -1 or end_idx <= start_idx):
                        raise ValueError("JSON êµ¬ì¡°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                        
                    json_str = response_text[start_idx:end_idx]
                    logger.debug(f"ğŸ“‹ ì¶”ì¶œëœ JSON:\n{json_str}")
                    
                    gpt_response = json.loads(json_str)
                    logger.info("âœ… JSON íŒŒì‹± ì„±ê³µ")

                except json.JSONDecodeError as e:
                    logger.error(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                    logger.error(f"ğŸ“„ íŒŒì‹± ì‹œë„í•œ í…ìŠ¤íŠ¸:\n{json_str if 'json_str' in locals() else 'None'}")
                    raise ValueError("JSON íŒŒì‹± ì‹¤íŒ¨")

                # 3. ì¶”ì²œ ëª©ë¡ ìƒì„±
                recommendations = []
                for rec in gpt_response.get("recommendations", []):
                    matched_diffuser = next(
                        (d for d in self.all_diffusers if d["id"] == rec["id"]), 
                        None
                    )

                    if matched_diffuser:
                        recommendations.append({
                            "id": matched_diffuser["id"],
                            "name": matched_diffuser["name_kr"], 
                            "brand": matched_diffuser["brand"],
                            "reason": rec.get("reason", "ì¶”ì²œ ì´ìœ  ì—†ìŒ"),
                            "situation": rec.get("situation", "ì‚¬ìš© ìƒí™© ì—†ìŒ")
                        })

                if not recommendations:
                    logger.error("âŒ ìœ íš¨í•œ ì¶”ì²œ ê²°ê³¼ ì—†ìŒ")
                    raise ValueError("ìœ íš¨í•œ ì¶”ì²œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")

                # 4. ê³µí†µ line_id ì°¾ê¸°
                common_line_id = self.get_common_line_id(recommendations)
                logger.info(f"âœ… ê³µí†µ ê³„ì—´ ID: {common_line_id}")

                response_data = {
                    "recommendations": recommendations,
                    "content": gpt_response.get("content", "ì¶”ì²œ ë¶„ì„ ì‹¤íŒ¨"),
                    "line_id": common_line_id
                }

                return response_data

            except ValueError as ve:
                logger.error(f"âŒ ì¶”ì²œ ì²˜ë¦¬ ì˜¤ë¥˜: {ve}")
                raise HTTPException(status_code=400, detail=str(ve))
            except Exception as e:
                logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
                raise HTTPException(status_code=500, detail="ì¶”ì²œ ìƒì„± ì‹¤íŒ¨")

        except json.JSONDecodeError as e:
            logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            raise HTTPException(status_code=500, detail="ì¶”ì²œ JSON íŒŒì‹± ì‹¤íŒ¨")
        except Exception as e:
            logger.error(f"ì¶”ì²œ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            raise HTTPException(status_code=500, detail="ì¶”ì²œ ìƒì„± ì‹¤íŒ¨")

    def decide_product_category(self, user_input: str) -> int:
        """
        This function uses GPT to determine whether the user is asking for a diffuser (2) or a perfume (1).
        It returns 2 (default) if the user asks for neither or if there is an error.
        """
        product_category_prompt = f"""
        Given the user input, determine whether the user is asking for a diffuser or a perfume recommendation. 
        1. Perfume (í–¥ìˆ˜ ì¶”ì²œ)
        2. Diffuser (ë””í“¨ì € ì¶”ì²œ)

        If the user is asking for a diffuser recommendation, return 2.
        If the user is asking for a perfume recommendation, return 1.
        If the request is for neither, return 2 by default.

        Respond with only a number: 1 or 2.

        ### Example 1:
        User input: "ê¸°ë¶„ ì¢‹ì€ í–¥ê¸°ê°€ ë‚˜ëŠ” ë””í“¨ì €ë¥¼ ì¶”ì²œí•´ì¤˜."
        Response: 2

        ### Example 2:
        User input: "í”¼ë¡œë¥¼ í’€ì–´ì£¼ëŠ” í–¥ìˆ˜ë¥¼ ì¶”ì²œí•´ì¤˜."
        Response: 1

        ### Example 3:
        User input: "ìŠ¤íŠ¸ë ˆìŠ¤ í•´ì†Œì— ë„ì›€ì´ ë˜ëŠ” ì œí’ˆì„ ì¶”ì²œí•´ì¤˜."
        Response: 2

        ### Important Rule:
        If the user input mentions í–¥ìˆ˜ (perfume), return 1.
        If the input mentions ë””í“¨ì € (diffuser) or does not mention either, return 2.

        User input: {user_input}
        Response: 
        """

        category_id = 2  # Default category_id is set to 2 (for diffuser)
        product_category_response = self.gpt_client.generate_response(product_category_prompt).strip()

        if product_category_response:
            try:
                category_id = int(product_category_response)
            except ValueError:
                category_id = 2
        logger.info(f"ğŸ€ ì¹´í…Œê³ ë¦¬ id: {category_id}")

        return category_id

    def analyze_user_input_effect(self, user_input: str) -> list:
        """
        This function uses GPT to analyze the user's input and return a list of primary effects (as integers).
        It returns [3] (Refreshing) by default in case of an error or invalid response.
        """
        user_input_effect_prompt = f"""
        Given the user input "{user_input}", identify the primary effect or effects the user is seeking among the following categories:
        1. Stress Reduction (ìŠ¤íŠ¸ë ˆìŠ¤ ê°ì†Œ)
        2. Happiness (í–‰ë³µ)
        3. Refreshing (ë¦¬í”„ë ˆì‹œ)
        4. Sleep Aid (ìˆ˜ë©´)
        5. Concentration (ì§‘ì¤‘)
        6. Energy Boost (ì—ë„ˆì§€)
        Respond with only a number or numbers separated by commas.

        ### Example 1:
        Input: "ìš”ì¦˜ ì ì„ ì˜ ëª»ìëŠ”ë° ìˆ˜ë©´ì— ë„ì›€ì´ ë ë§Œí•œ ë””í“¨ì €ë¥¼ ì¶”ì²œí•´ì¤˜."
        Output: 4

        ### Example 2:
        Input: "ê¸°ë¶„ì „í™˜ì— ë„ì›€ì´ ë ë§Œí•œ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•´ì¤˜."
        Output: 3, 6

        ### Example 3:
        Input: "ìš”ì¦˜ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë°›ì•˜ë”ë‹ˆ ì¢€ ê¸°ë¶„ì´ ì³ì ¸. ê¸°ë¶„ì„ ì—…ë˜ê²Œ í• ë§Œí•œ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•´ì¤˜."
        Output: 1"""

        user_input_effect_response = self.gpt_client.generate_response(user_input_effect_prompt).strip()
        try:
            user_input_effect_list = [int(x) for x in user_input_effect_response.split(',')]
        except ValueError:
            user_input_effect_list = [3]  # Default to [3] (Refreshing) if there's an error
        logger.info(f"ğŸ€ ì‚¬ìš©ì ìš”êµ¬ íš¨ëŠ¥ ë¦¬ìŠ¤íŠ¸: {user_input_effect_list}")

        return user_input_effect_list

    def generate_therapeutic_purpose_recommendation_response(self, user_input: str) -> dict:
        """í…Œë¼í”¼ ê¸°ë°˜ í–¥ìˆ˜/ë””í“¨ì € ì¶”ì²œ"""
        try:
            logger.info(f"ğŸŒ í…Œë¼í”¼ ê¸°ë°˜ í–¥ìˆ˜/ë””í“¨ì € ì¶”ì²œ ì‹œì‘: {user_input}")
            
            # Get the product category
            category_id = self.decide_product_category(user_input)

            # Analyze user input effects
            user_input_effect_list = self.analyze_user_input_effect(user_input)

            if category_id == 2:
                all_products = self.all_diffusers
                template = self.prompt_loader.get_prompt("diffuser_recommendation")
            else:
                all_products = self.db_service.load_cached_perfume_data()
                template = self.prompt_loader.get_prompt("recommendation")
                
            # Load note cache and spice therapeutic effect cache
            note_cache = self.db_service.load_cached_note_data()
            spice_effect_cache = self.db_service.load_cached_spice_therapeutic_effect_data()
            
            # Create a map of spice_id to effect
            spice_effect_map = {entry["id"]: entry["effect"] for entry in spice_effect_cache}
            
            # Filter notes that have note_type as "MIDDLE" or "SINGLE" and match user input effects
            valid_notes = [note for note in note_cache 
                        if note["note_type"] in ("MIDDLE", "SINGLE") 
                        and spice_effect_map.get(note["spice_id"]) in user_input_effect_list]
            
            # Get product IDs that match the valid notes
            valid_product_ids = {note["product_id"] for note in valid_notes}
            
            # Filter all_products based on valid product IDs
            filtered_products = [product for product in all_products if product["id"] in valid_product_ids]
            random.shuffle(filtered_products)
            selected_products = filtered_products[:20]
            
            purposes = {
                1: "Stress Reduction",
                2: "Happiness",
                3: "Refreshing",
                4: "Sleep Aid",
                5: "Concentration",
                6: "Energy Boost"
            }

            purpose = ", ".join([purposes[i] for i in user_input_effect_list])

            # Create a map of spice_id to name for easy lookup
            spice_name_map = {entry["id"]: entry["name_en"] for entry in spice_effect_cache}

            # Create a mapping of product_id to its MIDDLE/SINGLE spices
            product_spice_map = {}

            for note in note_cache:
                if note["note_type"] in ("MIDDLE", "SINGLE") and note["product_id"] in {p["id"] for p in selected_products}:
                    product_id = note["product_id"]
                    spice_name = spice_name_map.get(note["spice_id"], "Unknown Spice")

                    if product_id not in product_spice_map:
                        product_spice_map[product_id] = []
                    
                    product_spice_map[product_id].append(spice_name)

            products_text = "\n".join(
                f"{product['id']}. {product['name_kr']} ({product['brand']}): {', '.join(product_spice_map.get(product['id'], []))}"
                for product in selected_products
            )

            if category_id == 2:
                prompt = (
                    f"{template['description']}\n"
                    f"{template['rules']}\n"
                    f"ì‚¬ìš©ìì˜ user_input: {user_input}\n\n"
                    f"ë””í“¨ì € ì¶”ì²œ ëª©ì : {purpose}\n\n"
                    f"user_inputê³¼ ì¶”ì²œ ëª©ì ì„ ê³ ë ¤í•˜ì—¬ ë””í“¨ì €ë¥¼ ì¶”ì²œí•˜ì„¸ìš”:\n"
                    f"{user_input}\n\n"
                    f"ë””í“¨ì € ëª©ë¡(id. name (brand): spices):\n{products_text}\n"
                    f"ë””í“¨ì €ì˜ ë¸Œëœë“œ ì´ë¦„ì€ í¬í•¨í•˜ì§€ ì•Šì€ id,nameë§Œ í¬í•¨í•˜ì—¬ ë””í“¨ì €ë¥¼ 2ê°œ ì¶”ì²œí•´ì£¼ì„¸ìš”.\n\n"
                    f"- content: user_inputê³¼ ì¶”ì²œ ëª©ì ì„ ë°”íƒ•ìœ¼ë¡œ ë””í“¨ì €ë¥¼ ì¶”ì²œ ëª©ì ì— ë§ê²Œ ì¶”ì²œí•œ ì´ìœ ì™€ ì‚¬ìš© ìƒí™©, ë””í“¨ì €ë“¤ì˜ ì¶”ì²œ ëª©ì ì— ë”°ë¥¸ ê³µí†µì ì¸ ëŠë‚Œì„ í•¨ê»˜ ì ì–´ì£¼ì„¸ìš”.\n"
                    "ì•„ë˜ ì˜ˆì‹œëŠ” ë””í“¨ì €ì˜ ì¶”ì²œ ëª©ì ì´ ìŠ¤íŠ¸ë ˆìŠ¤ ì™„í™”ì¼ ë•Œì˜ ì˜ˆì‹œ ì…ë‹ˆë‹¤.\n"
                    "ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:\n"
                    "```json\n"
                    "{\n"
                    '  "recommendations": [\n'
                    '    {\n'
                    '      "id": 1503,\n'
                    '      "name": "ë ˆì§€ì˜¤ ë””í“¨ì €",\n'
                    '      "reason": "ë¼ë²¤ë”ì™€ ë² ë¥´ê°€ëª»ì˜ ì¡°í™”ë¡œìš´ í–¥ì´ ë§ˆìŒì„ í¸ì•ˆí•˜ê²Œ ë§Œë“¤ì–´ ì£¼ë©°, ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ì™„í™”í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤. ì€ì€í•œ ììŠ¤ë¯¼ì´ ë¶€ë“œëŸ¬ìš´ í”Œë¡œëŸ´ ê°ê°ì„ ë”í•´ì£¼ê³ , ë¨¸ìŠ¤í¬ì˜ í¬ê·¼í•œ ì”í–¥ì´ ì•ˆì •ê°ì„ ì„ ì‚¬í•˜ì—¬ ê¸´ì¥ëœ ëª¸ê³¼ ë§ˆìŒì„ í¸ì•ˆí•˜ê²Œ ê°ì‹¸ì¤ë‹ˆë‹¤. í•˜ë£¨ì˜ í”¼ë¡œë¥¼ í’€ê³  íœ´ì‹ì„ ì·¨í•˜ê¸°ì— ì í•©í•œ í–¥ìœ¼ë¡œ, ì¡°ìš©í•œ ê³µê°„ì—ì„œ ë§ˆìŒì„ ì§„ì •ì‹œí‚¤ê³  ì‹¶ì„ ë•Œ ì¶”ì²œí•©ë‹ˆë‹¤.",\n'
                    '      "situation": "í•˜ë£¨ ì¼ê³¼ë¥¼ ë§ˆì¹œ í›„ í¸ì•ˆí•œ íœ´ì‹ì„ ì·¨í•˜ê³  ì‹¶ì„ ë•Œ, ì¡°ìš©í•œ ê³µê°„ì—ì„œ ëª…ìƒì´ë‚˜ ë…ì„œë¥¼ í•˜ë©° ë§ˆìŒì„ ì•ˆì •ì‹œí‚¤ê³  ì‹¶ì„ ë•Œ, ë˜ëŠ” ìŠ¤íŠ¸ë ˆìŠ¤ë¡œ ì¸í•´ ì‰½ê²Œ ì ë“¤ê¸° ì–´ë ¤ìš´ ë°¤ì— ìˆ™ë©´ì„ ë•ê¸° ìœ„í•´ ì‚¬ìš©"\n'
                    '    },\n'
                    '    {\n'
                    '      "id": 1478,\n'
                    '      "name": "ì¹´í˜ ì†Œì‚¬ì´ì–´íŠ¸ í¼í“¸ ê±´",\n'
                    '      "reason": "íŒŒì´ë¦¬ì™€ ì•°ë²„ì˜ ë”°ëœ»í•˜ê³  ê¹Šì€ í–¥ì´ ëª¸ê³¼ ë§ˆìŒì„ í¸ì•ˆí•˜ê²Œ ê°ì‹¸ì£¼ë©°, ë¼ë²¤ë”ì˜ ë¶€ë“œëŸ½ê³  í—ˆë¸Œ ê°™ì€ í–¥ì´ ê¸´ì¥ì„ ì™„í™”í•˜ê³  ì•ˆì •ê°ì„ ì¤ë‹ˆë‹¤. ì€ì€í•˜ë©´ì„œë„ ì°¨ë¶„í•œ ë¶„ìœ„ê¸°ë¥¼ ì—°ì¶œí•˜ì—¬ ìŠ¤íŠ¸ë ˆìŠ¤ì™€ í”¼ë¡œë¥¼ ëœì–´ì£¼ê³  í¸ì•ˆí•œ íœ´ì‹ì„ ë•ìŠµë‹ˆë‹¤.",\n'
                    '      "situation": "í•˜ë£¨ë¥¼ ë§ˆë¬´ë¦¬í•˜ë©° ì¡°ìš©í•œ íœ´ì‹ì„ ì·¨í•˜ê³  ì‹¶ì„ ë•Œ, ë”°ëœ»í•œ ì¡°ëª… ì•„ë˜ì—ì„œ ë…ì„œë¥¼ í•˜ê±°ë‚˜ ëª…ìƒì„ í•  ë•Œ ì‚¬ìš©í•˜ë©´ ë§ˆìŒì´ ì°¨ë¶„í•´ì§€ê³  ì•ˆì •ê°ì„ ëŠë‚„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ìŠ¤íŠ¸ë ˆìŠ¤ë¡œ ì§€ì¹œ ë‚ , í¸ì•ˆí•œ ë¶„ìœ„ê¸° ì†ì—ì„œ ë‚˜ë§Œì˜ ì‹œê°„ì„ ì¦ê¸°ê³  ì‹¶ì„ ë•Œ í™œìš©í•˜ë©´ ì¢‹ìŠµë‹ˆë‹¤."\n'
                    '    }\n'
                    '  ],\n'
                    '  "content": "ë¶€ë“œëŸ½ê³  ë”°ëœ»í•œ í–¥ì´ ì¡°í™”ë¥¼ ì´ë£¨ì–´ ìŠ¤íŠ¸ë ˆìŠ¤ë¡œ ì§€ì¹œ ë§ˆìŒì„ í¸ì•ˆí•˜ê²Œ ê°ì‹¸ì¤ë‹ˆë‹¤. í¬ê·¼í•˜ê³  ì•ˆì •ì ì¸ ì”í–¥ì´ ê³µê°„ì„ ê°ì‹¸ë©° ê¸´ì¥ì„ í’€ì–´ì£¼ê³ , ì°¨ë¶„í•˜ê³  ì•„ëŠ‘í•œ ë¶„ìœ„ê¸°ë¥¼ ì—°ì¶œí•˜ì—¬ í•˜ë£¨ì˜ í”¼ë¡œë¥¼ ëœì–´ì£¼ëŠ” ë° ë„ì›€ì„ ì£¼ëŠ” í–¥ì…ë‹ˆë‹¤."'
                    '}\n'
                    "```"
                )
            else:
                prompt = (
                    f"{template['description']}\n"
                    f"{template['rules']}\n"
                    f"ì‚¬ìš©ìì˜ user_input: {user_input}\n\n"
                    f"í–¥ìˆ˜ ì¶”ì²œ ëª©ì : {purpose}\n\n"
                    f"user_inputê³¼ ì¶”ì²œ ëª©ì ì„ ê³ ë ¤í•˜ì—¬ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•˜ì„¸ìš”:\n"
                    f"{user_input}\n\n"
                    f"í–¥ìˆ˜ ëª©ë¡(id. name (brand): spices):\n{products_text}\n"
                    f"í–¥ìˆ˜ì˜ ë¸Œëœë“œ ì´ë¦„ì€ í¬í•¨í•˜ì§€ ì•Šì€ id,nameë§Œ í¬í•¨í•˜ì—¬ í–¥ìˆ˜ë¥¼ 3ê°œ ì¶”ì²œí•´ì£¼ì„¸ìš”.\n\n"
                    f"- content: user_inputê³¼ ì¶”ì²œ ëª©ì ì„ ë°”íƒ•ìœ¼ë¡œ í–¥ìˆ˜ë¥¼ ì¶”ì²œ ëª©ì ì— ë§ê²Œ ì¶”ì²œí•œ ì´ìœ ì™€ ì‚¬ìš© ìƒí™©, í–¥ìˆ˜ë“¤ì˜ ì¶”ì²œ ëª©ì ì— ë”°ë¥¸ ê³µí†µì ì¸ ëŠë‚Œì„ í•¨ê»˜ ì ì–´ì£¼ì„¸ìš”.\n"
                    "ì•„ë˜ ì˜ˆì‹œëŠ” í–¥ìˆ˜ì˜ ì¶”ì²œ ëª©ì ì´ ìŠ¤íŠ¸ë ˆìŠ¤ ì™„í™”ì¼ ë•Œì˜ ì˜ˆì‹œ ì…ë‹ˆë‹¤.\n"
                    "ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:\n"
                    "```json\n"
                    "{\n"
                    '  "recommendations": [\n'
                    '    {\n'
                    '      "id": 403,\n'
                    '      "name": "ìŸˆë„ë¥´ ë¡¤ëŸ¬ í„ ì˜¤ ë“œ í¼í“¸",\n'
                    '      "reason": "ë¶€ë“œëŸ½ê³  ìš°ì•„í•œ í”Œë¡œëŸ´ í–¥ì´ ê°ê°ì ìœ¼ë¡œ í¼ì§€ë©°, ê¸´ì¥ëœ ë§ˆìŒì„ í¸ì•ˆí•˜ê²Œ ì§„ì •ì‹œí‚¤ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤. í’ì„±í•˜ê³  ë”°ëœ»í•œ ê½ƒí–¥ê¸°ê°€ í¬ê·¼í•œ ê°ì„±ì„ ìì•„ë‚´ì–´ ìŠ¤íŠ¸ë ˆìŠ¤ ì†ì—ì„œë„ ì•ˆì •ê°ì„ ëŠë‚„ ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤. ìì—°ìŠ¤ëŸ½ê³  ì¡°í™”ë¡œìš´ í–¥ì˜ íë¦„ì´ ë§ˆìŒì„ ë¶€ë“œëŸ½ê²Œ ì–´ë£¨ë§Œì ¸ í•˜ë£¨ì˜ í”¼ë¡œë¥¼ í’€ê³  í‰ì˜¨í•œ ë¶„ìœ„ê¸°ë¥¼ ì—°ì¶œí•©ë‹ˆë‹¤.",\n'
                    '      "situation": "í•˜ë£¨ë¥¼ ë§ˆë¬´ë¦¬í•˜ë©° í¸ì•ˆí•œ ì‹œê°„ì„ ë³´ë‚´ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•˜ë©´ ì¢‹ìŠµë‹ˆë‹¤. ì €ë… íœ´ì‹ ì‹œê°„ì— ê°€ë³ê²Œ ë°œë¼ ê¹Šì€ ìˆ¨ì„ ë“¤ì´ë§ˆì‹œë©´, ë¶€ë“œëŸ¬ìš´ ê½ƒí–¥ê¸°ê°€ ë§ˆìŒì„ ì°¨ë¶„í•˜ê²Œ ê°ì‹¸ì£¼ë©° ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ì™„í™”í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤. ë˜í•œ ë”°ëœ»í•œ ì°¨ í•œ ì”ê³¼ í•¨ê»˜ ì¡°ìš©í•œ ì‹œê°„ì„ ë³´ë‚´ê±°ë‚˜, ìŠ¤íŒŒë‚˜ ëª©ìš• í›„ ëª¸ê³¼ ë§ˆìŒì„ ì•ˆì •ì‹œí‚¤ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•˜ë©´ ë”ìš± í¸ì•ˆí•œ ë¶„ìœ„ê¸°ë¥¼ ëŠë‚„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."\n'
                    '    },\n'
                    '    {\n'
                    '      "id": 765,\n'
                    '      "name": "ìœ„ìŠ¤í¼ ì¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜¤ ë“œ ëšœì™ˆë ›",\n'
                    '      "reason": "ë”°ëœ»í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë°”ë‹ë¼ í–¥ì´ ê°ê°ì„ í¸ì•ˆí•˜ê²Œ ê°ì‹¸ì£¼ë©°, ìš°ë”” ë…¸íŠ¸ì™€ ì‹œë”ìš°ë“œì˜ ì°¨ë¶„í•œ ê¹Šì´ê°€ ì•ˆì •ê°ì„ ë”í•´ì¤ë‹ˆë‹¤. ì€ì€í•œ í˜í¼ì˜ ê°€ë²¼ìš´ ìŠ¤íŒŒì´ì‹œí•¨ì´ ë¶€ë‹´ìŠ¤ëŸ½ì§€ ì•Šê²Œ ì¡°í™”ë¥¼ ì´ë£¨ì–´, ë”°ëœ»í•˜ë©´ì„œë„ ê³ ìš”í•œ ë¶„ìœ„ê¸°ë¥¼ ì—°ì¶œí•©ë‹ˆë‹¤. ì´ í–¥ì€ ë³µì¡í•œ ìƒê°ì„ ì •ë¦¬í•˜ê³  ë§ˆìŒì˜ ê¸´ì¥ì„ í’€ì–´ì£¼ëŠ” ë° ë„ì›€ì„ ì£¼ë©°, ì¡°ìš©í•œ ìˆœê°„ì„ ë”ìš± í¸ì•ˆí•˜ê³  ì•„ëŠ‘í•˜ê²Œ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.",\n'
                    '      "situation": "ê³ ìš”í•œ ë¶„ìœ„ê¸° ì†ì—ì„œ ë§ˆìŒì„ ì°¨ë¶„í•˜ê²Œ ê°€ë¼ì•‰íˆê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•˜ê¸° ì¢‹ìŠµë‹ˆë‹¤. ë…ì„œí•˜ë©° ê¹Šì€ ëª°ì…ê°ì„ ëŠë¼ê³  ì‹¶ì„ ë•Œ, ë¹„ ì˜¤ëŠ” ë‚  ì°½ê°€ì—ì„œ ë”°ëœ»í•œ ì°¨ í•œ ì”ê³¼ í•¨ê»˜ ì—¬ìœ ë¡œìš´ ì‹œê°„ì„ ë³´ë‚´ê³  ì‹¶ì„ ë•Œ, í˜¹ì€ í•˜ë£¨ë¥¼ ë§ˆë¬´ë¦¬í•˜ë©° ì¡°ìš©í•œ ìŒì•…ê³¼ í•¨ê»˜ ê¸´ì¥ì„ í’€ê³  í¸ì•ˆí•œ íœ´ì‹ì„ ì·¨í•˜ê³  ì‹¶ì„ ë•Œ ì–´ìš¸ë¦¬ëŠ” í–¥ì…ë‹ˆë‹¤."\n'
                    '    }\n'
                    '    {\n'
                    '      "id": 694,\n'
                    '      "name": "ë² ë¥´ê°€ëª» 22 ì˜¤ ë“œ í¼í“¸",\n'
                    '      "reason": "ë² ë¥´ê°€ëª»ê³¼ ìëª½ì˜ ìƒì¾Œí•˜ê³  ì‹ ì„ í•œ í–¥ì´ ê¸°ë¶„ì„ ì „í™˜ì‹œí‚¤ê³ , ì˜¤ë Œì§€ ë¸”ë¡œì„¬ê³¼ í˜í‹°ê·¸ë ˆì¸ì—ì„œ ëŠê»´ì§€ëŠ” ë¶€ë“œëŸ¬ìš´ ê½ƒí–¥ê¸°ê°€ ë§ˆìŒì„ í¸ì•ˆí•˜ê²Œ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤. ë˜í•œ, ë¨¸ìŠ¤í¬ì™€ ì•°ë²„ê°€ ì¡°í™”ë¥¼ ì´ë£¨ì–´ ë”°ëœ»í•˜ê³  ì•ˆì •ì ì¸ ë¶„ìœ„ê¸°ë¥¼ ì¡°ì„±í•˜ë©°, ì‹œë”ì™€ ë² í‹°ë²„ì˜ ê¹Šì´ ìˆëŠ” í–¥ì´ ë§ˆìŒì„ ì°¨ë¶„í•˜ê²Œ ì•ˆì •ì‹œì¼œ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ í•´ì†Œí•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤. ì´ í–¥ìˆ˜ëŠ” ë³µì¡í•œ ìƒê°ì„ ì •ë¦¬í•˜ê³  í‰ì˜¨í•œ ìƒíƒœë¡œ ì´ëŒì–´ì£¼ëŠ” íš¨ê³¼ê°€ ìˆìŠµë‹ˆë‹¤.",\n'
                    '      "situation": "ì—…ë¬´ë‚˜ ì¤‘ìš”í•œ ì¼ë¡œ ì¸í•œ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ í•´ì†Œí•˜ê³  ì‹¶ì„ ë•Œ í˜¹ì€ ê¸´ì¥ì„ í’€ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•˜ë©´ ì¢‹ìŠµë‹ˆë‹¤. ë˜í•œ, ì°¨ í•œ ì”ê³¼ í•¨ê»˜ ì—¬ìœ ë¡œìš´ ì‹œê°„ì„ ë³´ë‚´ê³  ì‹¶ì„ ë•Œë‚˜, í¸ì•ˆí•œ íœ´ì‹ì„ ì·¨í•˜ê³  ì‹¶ì„ ë•Œ ì´ í–¥ìˆ˜ë¥¼ ë¿Œë¦¬ë©´, ìƒì¾Œí•˜ë©´ì„œë„ ì•ˆì •ê° ìˆëŠ” í–¥ì´ ë§ˆìŒì„ ì§„ì •ì‹œí‚¤ê³  í¸ì•ˆí•œ ë¶„ìœ„ê¸°ë¥¼ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤."\n'
                    '    }\n'
                    '  ],\n'
                    '  "content": "ë¶€ë“œëŸ½ê³  ë”°ëœ»í•œ í–¥ë“¤ì´ ê°ê°ì„ ê°ì‹¸ë©°, ê³ ìš”í•˜ê³  ì°¨ë¶„í•œ ë¶„ìœ„ê¸°ë¥¼ ë§Œë“¤ì–´ ë§ˆìŒì„ ì•ˆì •ì‹œí‚µë‹ˆë‹¤. í–¥ë“¤ì´ ìì—°ìŠ¤ëŸ½ê²Œ í¼ì§€ë©° ê¸´ì¥ì„ í’€ì–´ì£¼ê³ , í¸ì•ˆí•˜ê³  í‰ì˜¨í•œ ì‹œê°„ì„ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤. ì´ ë””í“¨ì €ë“¤ì€ ë³µì¡í•œ ìƒê°ì„ ì •ë¦¬í•˜ê³  ë§ˆìŒì„ ì§„ì •ì‹œí‚¤ëŠ” ë° ë„ì›€ì„ ì£¼ë©°, í•˜ë£¨ì˜ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ í•´ì†Œí•  ìˆ˜ ìˆëŠ” ìµœì ì˜ ì„ íƒì´ ë  ê²ƒì…ë‹ˆë‹¤."'
                    '}\n'
                    "```"
                )
            
            try:
                logger.info("ğŸ”„ í–¥ìˆ˜/ë””í“¨ì € ì¶”ì²œ ì²˜ë¦¬ ì‹œì‘")
                
                # 1. GPT ì‘ë‹µ ë°›ê¸°
                logger.info("ğŸ¤– GPT ì‘ë‹µ ìš”ì²­")
                response_text = self.gpt_client.generate_response(prompt)
                logger.debug(f"ğŸ“ GPT ì›ë³¸ ì‘ë‹µ:\n{response_text}")

                # 2. JSON íŒŒì‹±
                try:
                    # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
                    if '```' in response_text:
                        parts = response_text.split('```')
                        for part in parts:
                            if '{' in part and '}' in part:
                                response_text = part.strip()
                                if response_text.startswith('json'):
                                    response_text = response_text[4:].strip()
                                break

                    # JSON êµ¬ì¡° ì¶”ì¶œ
                    start_idx = response_text.find('{')
                    end_idx = response_text.rfind('}') + 1
                    if (start_idx == -1 or end_idx <= start_idx):
                        raise ValueError("JSON êµ¬ì¡°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                        
                    json_str = response_text[start_idx:end_idx]
                    logger.debug(f"ğŸ“‹ ì¶”ì¶œëœ JSON:\n{json_str}")
                    
                    gpt_response = json.loads(json_str)
                    logger.info("âœ… JSON íŒŒì‹± ì„±ê³µ")

                except json.JSONDecodeError as e:
                    logger.error(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                    logger.error(f"ğŸ“„ íŒŒì‹± ì‹œë„í•œ í…ìŠ¤íŠ¸:\n{json_str if 'json_str' in locals() else 'None'}")
                    raise ValueError("JSON íŒŒì‹± ì‹¤íŒ¨")

                # 3. ì¶”ì²œ ëª©ë¡ ìƒì„±
                recommendations = []
                for rec in gpt_response.get("recommendations", []):
                    matched_product = next(
                        (d for d in selected_products if d["id"] == rec["id"]), 
                        None
                    )

                    if matched_product:
                        recommendations.append({
                            "id": matched_product["id"],
                            "name": matched_product["name_kr"], 
                            "brand": matched_product["brand"],
                            "reason": rec.get("reason", "ì¶”ì²œ ì´ìœ  ì—†ìŒ"),
                            "situation": rec.get("situation", "ì‚¬ìš© ìƒí™© ì—†ìŒ")
                        })

                if not recommendations:
                    logger.error("âŒ ìœ íš¨í•œ ì¶”ì²œ ê²°ê³¼ ì—†ìŒ")
                    raise ValueError("ìœ íš¨í•œ ì¶”ì²œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")

                # 4. ê³µí†µ line_id ì°¾ê¸°
                common_line_id = self.get_common_line_id(recommendations)
                logger.info(f"âœ… ê³µí†µ ê³„ì—´ ID: {common_line_id}")

                response_data = {
                    "recommendations": recommendations,
                    "content": gpt_response.get("content", "ì¶”ì²œ ë¶„ì„ ì‹¤íŒ¨"),
                    "line_id": common_line_id
                }

                return response_data

            except ValueError as ve:
                logger.error(f"âŒ ì¶”ì²œ ì²˜ë¦¬ ì˜¤ë¥˜: {ve}")
                raise HTTPException(status_code=400, detail=str(ve))
            except Exception as e:
                logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
                raise HTTPException(status_code=500, detail="ì¶”ì²œ ìƒì„± ì‹¤íŒ¨")
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            raise HTTPException(status_code=500, detail="ì¶”ì²œ JSON íŒŒì‹± ì‹¤íŒ¨")
        except Exception as e:
            logger.error(f"ì¶”ì²œ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            raise HTTPException(status_code=500, detail="ì¶”ì²œ ìƒì„± ì‹¤íŒ¨")